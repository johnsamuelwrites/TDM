{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP 6 : Docker pour les Pipelines de Traitement de Donn\u00e9es\n",
    "\n",
    "## Objectifs\n",
    "\n",
    "Ce TP pr\u00e9sente la conteneurisation avec Docker pour construire des pipelines de traitement de donn\u00e9es reproductibles et \u00e9volutifs. Vous apprendrez \u00e0 empaqueter des applications, g\u00e9rer des environnements multi-conteneurs et d\u00e9ployer des flux de traitement de donn\u00e9es.\n",
    "\n",
    "### Objectifs p\u00e9dagogiques\n",
    "* Comprendre l'architecture Docker et les concepts de conteneurisation\n",
    "* \u00c9crire des Dockerfiles pour empaqueter des applications Python\n",
    "* Utiliser Docker Compose pour l'orchestration multi-conteneurs\n",
    "* Impl\u00e9menter des pipelines de donn\u00e9es avec des volumes partag\u00e9s\n",
    "* Construire des mod\u00e8les producteur-consommateur avec des files de messages\n",
    "* Connecter des applications \u00e0 des bases de donn\u00e9es dans des conteneurs\n",
    "* Impl\u00e9menter des architectures frontend-backend\n",
    "* D\u00e9ployer et mettre \u00e0 l'\u00e9chelle des applications de traitement de donn\u00e9es\n",
    "\n",
    "### Pr\u00e9requis\n",
    "* Avoir termin\u00e9 le TP 5 (Apache Spark)\n",
    "* Docker Desktop install\u00e9 ([Guide d'installation](https://docs.docker.com/get-docker/))\n",
    "* Compr\u00e9hension de base des commandes Linux\n",
    "* Fondamentaux de la programmation Python\n",
    "\n",
    "### Installation\n",
    "\n",
    "V\u00e9rifiez que Docker est install\u00e9 :\n",
    "```bash\n",
    "docker --version\n",
    "docker-compose --version\n",
    "```\n",
    "\n",
    "### Aper\u00e7u des exercices\n",
    "\n",
    "| Exercice | Sujet | Difficult\u00e9 |\n",
    "|----------|-------|------------|\n",
    "| 1 | Fondamentaux de Docker et commandes de base | \u2605 |\n",
    "| 2 | \u00c9criture de Dockerfiles pour applications Python | \u2605 |\n",
    "| 3 | Docker Compose pour applications multi-conteneurs | \u2605\u2605 |\n",
    "| 4 | Pipelines de donn\u00e9es avec volumes partag\u00e9s | \u2605\u2605 |\n",
    "| 5 | Producteur-Consommateur avec files de messages | \u2605\u2605 |\n",
    "| 6 | Int\u00e9gration Application-Base de donn\u00e9es | \u2605\u2605 |\n",
    "| 7 | Architectures Frontend-Backend | \u2605\u2605\u2605 |\n",
    "| 8 | Mise \u00e0 l'\u00e9chelle et surveillance des conteneurs | \u2605\u2605\u2605 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercice 1 : Fondamentaux de Docker et commandes de base [\u2605]\n",
    "\n",
    "### Architecture Docker\n",
    "\n",
    "Docker utilise une architecture client-serveur :\n",
    "\n",
    "```\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                     H\u00f4te Docker                              \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502   Client    \u2502    \u2502          D\u00e9mon Docker              \u2502 \u2502\n\u2502  \u2502   Docker    \u2502\u25c4\u2500\u2500\u25ba\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510           \u2502 \u2502\n\u2502  \u2502   (CLI)     \u2502    \u2502  \u2502Conteneur\u2502  \u2502Conteneur\u2502           \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502  \u2502    1    \u2502  \u2502    2    \u2502           \u2502 \u2502\n\u2502                     \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518           \u2502 \u2502\n\u2502                     \u2502       \u2502            \u2502                 \u2502 \u2502\n\u2502                     \u2502  \u250c\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2510           \u2502 \u2502\n\u2502                     \u2502  \u2502      Images          \u2502           \u2502 \u2502\n\u2502                     \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518           \u2502 \u2502\n\u2502                     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "```\n",
    "\n",
    "### Concepts cl\u00e9s\n",
    "\n",
    "- **Image** : Mod\u00e8le en lecture seule avec des instructions pour cr\u00e9er un conteneur\n",
    "- **Conteneur** : Instance ex\u00e9cutable d'une image\n",
    "- **Dockerfile** : Fichier texte avec des instructions pour construire une image\n",
    "- **Registre** : Stockage pour les images Docker (ex. Docker Hub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commandes Docker de base\n",
    "\n",
    "Ex\u00e9cutez les commandes suivantes dans votre terminal pour vous familiariser avec Docker :\n",
    "\n",
    "```bash\n",
    "# V\u00e9rifier la version de Docker\n",
    "docker --version\n",
    "\n",
    "# Afficher les informations syst\u00e8me\n",
    "docker info\n",
    "\n",
    "# Lister les images disponibles\n",
    "docker images\n",
    "\n",
    "# Lister les conteneurs en cours d'ex\u00e9cution\n",
    "docker ps\n",
    "\n",
    "# Lister tous les conteneurs (y compris arr\u00eat\u00e9s)\n",
    "docker ps -a\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex\u00e9cuter votre premier conteneur\n",
    "\n",
    "```bash\n",
    "# Ex\u00e9cuter un simple conteneur hello-world\n",
    "docker run hello-world\n",
    "\n",
    "# Ex\u00e9cuter un conteneur Python interactif\n",
    "docker run -it python:3.10 python\n",
    "\n",
    "# Ex\u00e9cuter un conteneur avec une commande sp\u00e9cifique\n",
    "docker run python:3.10 python -c \"print('Bonjour depuis Docker !')\"\n",
    "\n",
    "# Ex\u00e9cuter un conteneur en arri\u00e8re-plan (mode d\u00e9tach\u00e9)\n",
    "docker run -d --name mon_python python:3.10 sleep 60\n",
    "\n",
    "# Arr\u00eater un conteneur en cours d'ex\u00e9cution\n",
    "docker stop mon_python\n",
    "\n",
    "# Supprimer un conteneur\n",
    "docker rm mon_python\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cycle de vie d'un conteneur\n",
    "\n",
    "```\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   docker run   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   docker stop   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Cr\u00e9\u00e9   \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba\u2502 En cours\u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba\u2502 Arr\u00eat\u00e9  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n     \u2502                          \u2502                           \u2502\n     \u2502                          \u2502 docker pause              \u2502\n     \u2502                          \u25bc                           \u2502\n     \u2502                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                       \u2502\n     \u2502                    \u2502 En pause\u2502                       \u2502\n     \u2502                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                       \u2502\n     \u2502                                                      \u2502\n     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                        docker rm\n",
    "```\n",
    "\n",
    "```bash\n",
    "# Afficher les logs d'un conteneur\n",
    "docker logs <container_id>\n",
    "\n",
    "# Ex\u00e9cuter une commande dans un conteneur en cours d'ex\u00e9cution\n",
    "docker exec -it <container_id> bash\n",
    "\n",
    "# Copier des fichiers vers/depuis un conteneur\n",
    "docker cp fichier_local.txt <container_id>:/chemin/dans/conteneur/\n",
    "docker cp <container_id>:/chemin/dans/conteneur/fichier.txt ./fichier_local.txt\n",
    "\n",
    "# Afficher l'utilisation des ressources des conteneurs\n",
    "docker stats\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions - Exercice 1\n",
    "\n",
    "**Q1.1** Ex\u00e9cutez un conteneur Python qui affiche la version de Python du syst\u00e8me, le nom du syst\u00e8me d'exploitation et la date/heure actuelle. Capturez la sortie.\n",
    "\n",
    "**Q1.2** Ex\u00e9cutez un conteneur Ubuntu de mani\u00e8re interactive. \u00c0 l'int\u00e9rieur du conteneur :\n",
    "- Mettez \u00e0 jour la liste des paquets\n",
    "- Installez `curl`\n",
    "- T\u00e9l\u00e9chargez une page web\n",
    "- Quittez le conteneur\n",
    "\n",
    "**Q1.3** Ex\u00e9cutez trois conteneurs en mode d\u00e9tach\u00e9 avec des noms diff\u00e9rents. Utilisez `docker ps` pour v\u00e9rifier qu'ils fonctionnent, puis arr\u00eatez et supprimez-les tous en utilisant une seule commande chacun."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercice 2 : \u00c9criture de Dockerfiles pour applications Python [\u2605]\n",
    "\n",
    "### Bases du Dockerfile\n",
    "\n",
    "Un Dockerfile est un script contenant des instructions pour construire une image Docker.\n",
    "\n",
    "### Instructions Dockerfile courantes\n",
    "\n",
    "| Instruction | Description |\n",
    "|-------------|-------------|\n",
    "| `FROM` | Image de base \u00e0 partir de laquelle d\u00e9marrer |\n",
    "| `WORKDIR` | D\u00e9finir le r\u00e9pertoire de travail |\n",
    "| `COPY` | Copier des fichiers de l'h\u00f4te vers l'image |\n",
    "| `RUN` | Ex\u00e9cuter des commandes pendant la construction |\n",
    "| `ENV` | D\u00e9finir des variables d'environnement |\n",
    "| `EXPOSE` | Documenter les ports \u00e9cout\u00e9s par le conteneur |\n",
    "| `CMD` | Commande par d\u00e9faut au d\u00e9marrage du conteneur |\n",
    "| `ENTRYPOINT` | Configurer le conteneur comme ex\u00e9cutable |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemple : Application Python simple\n",
    "\n",
    "Cr\u00e9ez un fichier `app.py` :\n",
    "\n",
    "```python\n",
    "# app.py\n",
    "import sys\n",
    "import platform\n",
    "from datetime import datetime\n",
    "\n",
    "def main():\n",
    "    print(f\"Version Python : {sys.version}\")\n",
    "    print(f\"Plateforme : {platform.platform()}\")\n",
    "    print(f\"Heure actuelle : {datetime.now()}\")\n",
    "    print(\"Bonjour depuis Docker !\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "```\n",
    "\n",
    "Cr\u00e9ez un `Dockerfile` :\n",
    "\n",
    "```dockerfile\n",
    "# Utiliser l'image Python officielle comme base\n",
    "FROM python:3.10-slim\n",
    "\n",
    "# D\u00e9finir le r\u00e9pertoire de travail\n",
    "WORKDIR /app\n",
    "\n",
    "# Copier le code de l'application\n",
    "COPY app.py .\n",
    "\n",
    "# D\u00e9finir la commande par d\u00e9faut\n",
    "CMD [\"python\", \"app.py\"]\n",
    "```\n",
    "\n",
    "Construire et ex\u00e9cuter :\n",
    "\n",
    "```bash\n",
    "# Construire l'image\n",
    "docker build -t mon-app-python .\n",
    "\n",
    "# Ex\u00e9cuter le conteneur\n",
    "docker run mon-app-python\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemple : Application Python avec d\u00e9pendances\n",
    "\n",
    "Cr\u00e9ez `requirements.txt` :\n",
    "\n",
    "```\n",
    "pandas==2.0.0\n",
    "numpy==1.24.0\n",
    "requests==2.28.0\n",
    "```\n",
    "\n",
    "Cr\u00e9ez `data_processor.py` :\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def process_data():\n",
    "    # Cr\u00e9er des donn\u00e9es exemple\n",
    "    data = {\n",
    "        'nom': ['Alice', 'Bob', 'Charlie', 'Diana'],\n",
    "        'valeur': np.random.randint(1, 100, 4)\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    print(\"R\u00e9sultats du traitement des donn\u00e9es :\")\n",
    "    print(df)\n",
    "    print(f\"\\nSomme : {df['valeur'].sum()}\")\n",
    "    print(f\"Moyenne : {df['valeur'].mean():.2f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_data()\n",
    "```\n",
    "\n",
    "`Dockerfile` optimis\u00e9 :\n",
    "\n",
    "```dockerfile\n",
    "FROM python:3.10-slim\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "# Copier d'abord les requirements (pour une meilleure mise en cache des couches)\n",
    "COPY requirements.txt .\n",
    "\n",
    "# Installer les d\u00e9pendances\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "# Copier le code de l'application\n",
    "COPY data_processor.py .\n",
    "\n",
    "CMD [\"python\", \"data_processor.py\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructions multi-\u00e9tapes\n",
    "\n",
    "Les constructions multi-\u00e9tapes aident \u00e0 cr\u00e9er des images de production plus l\u00e9g\u00e8res :\n",
    "\n",
    "```dockerfile\n",
    "# \u00c9tape de construction\n",
    "FROM python:3.10 AS builder\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "COPY requirements.txt .\n",
    "RUN pip install --user --no-cache-dir -r requirements.txt\n",
    "\n",
    "# \u00c9tape de production\n",
    "FROM python:3.10-slim\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "# Copier les paquets install\u00e9s depuis le builder\n",
    "COPY --from=builder /root/.local /root/.local\n",
    "\n",
    "# S'assurer que les scripts dans .local sont utilisables\n",
    "ENV PATH=/root/.local/bin:$PATH\n",
    "\n",
    "COPY app.py .\n",
    "\n",
    "CMD [\"python\", \"app.py\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonnes pratiques pour les Dockerfiles\n",
    "\n",
    "1. **Utiliser des tags d'image sp\u00e9cifiques** : `python:3.10-slim` au lieu de `python:latest`\n",
    "2. **Ordonner les instructions par fr\u00e9quence de changement** : Copier les requirements avant le code\n",
    "3. **Utiliser `.dockerignore`** : Exclure les fichiers inutiles\n",
    "4. **Minimiser les couches** : Combiner les commandes RUN li\u00e9es\n",
    "5. **Ne pas ex\u00e9cuter en root** : Cr\u00e9er un utilisateur non-root quand possible\n",
    "6. **Utiliser les constructions multi-\u00e9tapes** : Pour des images de production plus l\u00e9g\u00e8res\n",
    "\n",
    "Exemple `.dockerignore` :\n",
    "\n",
    "```\n",
    "__pycache__\n",
    "*.pyc\n",
    "*.pyo\n",
    ".git\n",
    ".gitignore\n",
    "*.md\n",
    ".env\n",
    "venv/\n",
    ".pytest_cache/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions - Exercice 2\n",
    "\n",
    "**Q2.1** Cr\u00e9ez un Dockerfile pour une application PySpark qui :\n",
    "- Utilise `bitnami/spark` comme image de base\n",
    "- Installe des paquets Python suppl\u00e9mentaires (pandas, matplotlib)\n",
    "- Copie un script Spark qui traite des donn\u00e9es CSV\n",
    "- Ex\u00e9cute le script au d\u00e9marrage du conteneur\n",
    "\n",
    "**Q2.2** Cr\u00e9ez un Dockerfile qui :\n",
    "- Utilise un utilisateur non-root pour la s\u00e9curit\u00e9\n",
    "- Impl\u00e9mente des v\u00e9rifications de sant\u00e9 (health checks)\n",
    "- Utilise des variables d'environnement pour la configuration\n",
    "- Inclut un \u00e9tiquetage correct (maintainer, version, description)\n",
    "\n",
    "**Q2.3** Comparez les tailles d'images de :\n",
    "- Un Dockerfile simple utilisant `python:3.10`\n",
    "- La m\u00eame application utilisant `python:3.10-slim`\n",
    "- Une version avec construction multi-\u00e9tapes\n",
    "\n",
    "Documentez les diff\u00e9rences de taille et expliquez quand chaque approche est appropri\u00e9e."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercice 3 : Docker Compose pour applications multi-conteneurs [\u2605\u2605]\n",
    "\n",
    "### Aper\u00e7u de Docker Compose\n",
    "\n",
    "Docker Compose vous permet de d\u00e9finir et d'ex\u00e9cuter des applications multi-conteneurs en utilisant un fichier YAML.\n",
    "\n",
    "### Structure de base de docker-compose.yml\n",
    "\n",
    "```yaml\n",
    "version: \"3.8\"\n",
    "\n",
    "services:\n",
    "  nom_service:\n",
    "    image: nom_image:tag\n",
    "    # OU construire depuis un Dockerfile\n",
    "    build: ./chemin/vers/dockerfile\n",
    "    ports:\n",
    "      - \"port_hote:port_conteneur\"\n",
    "    volumes:\n",
    "      - ./chemin/local:/chemin/conteneur\n",
    "    environment:\n",
    "      - NOM_VAR=valeur\n",
    "    depends_on:\n",
    "      - autre_service\n",
    "\n",
    "volumes:\n",
    "  volume_nomme:\n",
    "\n",
    "networks:\n",
    "  reseau_personnalise:\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commandes Docker Compose\n",
    "\n",
    "```bash\n",
    "# D\u00e9marrer tous les services\n",
    "docker-compose up\n",
    "\n",
    "# D\u00e9marrer en mode d\u00e9tach\u00e9\n",
    "docker-compose up -d\n",
    "\n",
    "# Construire les images avant de d\u00e9marrer\n",
    "docker-compose up --build\n",
    "\n",
    "# Arr\u00eater tous les services\n",
    "docker-compose down\n",
    "\n",
    "# Arr\u00eater et supprimer les volumes\n",
    "docker-compose down -v\n",
    "\n",
    "# Afficher les logs\n",
    "docker-compose logs\n",
    "docker-compose logs -f nom_service\n",
    "\n",
    "# Mettre \u00e0 l'\u00e9chelle un service\n",
    "docker-compose up --scale nom_service=3\n",
    "\n",
    "# Ex\u00e9cuter une commande dans un service\n",
    "docker-compose exec nom_service commande\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemple : Application Web avec Redis\n",
    "\n",
    "Cr\u00e9ez `app.py` :\n",
    "\n",
    "```python\n",
    "from flask import Flask\n",
    "import redis\n",
    "\n",
    "app = Flask(__name__)\n",
    "cache = redis.Redis(host='redis', port=6379)\n",
    "\n",
    "@app.route('/')\n",
    "def hello():\n",
    "    count = cache.incr('hits')\n",
    "    return f'Bonjour ! Cette page a \u00e9t\u00e9 vue {count} fois.'\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5000)\n",
    "```\n",
    "\n",
    "Cr\u00e9ez `requirements.txt` :\n",
    "\n",
    "```\n",
    "flask\n",
    "redis\n",
    "```\n",
    "\n",
    "Cr\u00e9ez `Dockerfile` :\n",
    "\n",
    "```dockerfile\n",
    "FROM python:3.10-slim\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "COPY requirements.txt .\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "COPY app.py .\n",
    "\n",
    "EXPOSE 5000\n",
    "\n",
    "CMD [\"python\", \"app.py\"]\n",
    "```\n",
    "\n",
    "Cr\u00e9ez `docker-compose.yml` :\n",
    "\n",
    "```yaml\n",
    "version: \"3.8\"\n",
    "\n",
    "services:\n",
    "  web:\n",
    "    build: .\n",
    "    ports:\n",
    "      - \"5000:5000\"\n",
    "    depends_on:\n",
    "      - redis\n",
    "    environment:\n",
    "      - FLASK_ENV=development\n",
    "\n",
    "  redis:\n",
    "    image: redis:alpine\n",
    "    volumes:\n",
    "      - redis_data:/data\n",
    "\n",
    "volumes:\n",
    "  redis_data:\n",
    "```\n",
    "\n",
    "Ex\u00e9cutez avec :\n",
    "\n",
    "```bash\n",
    "docker-compose up --build\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D\u00e9pendances de services et v\u00e9rifications de sant\u00e9\n",
    "\n",
    "```yaml\n",
    "version: \"3.8\"\n",
    "\n",
    "services:\n",
    "  web:\n",
    "    build: .\n",
    "    depends_on:\n",
    "      db:\n",
    "        condition: service_healthy\n",
    "    healthcheck:\n",
    "      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:5000/health\"]\n",
    "      interval: 30s\n",
    "      timeout: 10s\n",
    "      retries: 3\n",
    "\n",
    "  db:\n",
    "    image: postgres:15\n",
    "    healthcheck:\n",
    "      test: [\"CMD-SHELL\", \"pg_isready -U postgres\"]\n",
    "      interval: 5s\n",
    "      timeout: 5s\n",
    "      retries: 5\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions - Exercice 3\n",
    "\n",
    "**Q3.1** Cr\u00e9ez une configuration Docker Compose pour un pipeline de traitement de donn\u00e9es avec :\n",
    "- Un service g\u00e9n\u00e9rateur de donn\u00e9es Python\n",
    "- Un service Redis pour la mise en cache\n",
    "- Un service processeur de donn\u00e9es qui lit depuis Redis\n",
    "- Des d\u00e9pendances de services correctes\n",
    "\n",
    "**Q3.2** Modifiez l'exemple pr\u00e9c\u00e9dent pour utiliser :\n",
    "- Des r\u00e9seaux personnalis\u00e9s pour l'isolation des services\n",
    "- Des fichiers d'environnement (`.env`)\n",
    "- Des montages de volumes pour la persistance des donn\u00e9es\n",
    "\n",
    "**Q3.3** Cr\u00e9ez un fichier Docker Compose qui d\u00e9marre un serveur Jupyter Notebook avec :\n",
    "- Des biblioth\u00e8ques de science des donn\u00e9es pr\u00e9install\u00e9es (pandas, numpy, matplotlib, sklearn)\n",
    "- Un stockage persistant des notebooks\n",
    "- Acc\u00e8s \u00e0 un volume de donn\u00e9es partag\u00e9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercice 4 : Pipelines de donn\u00e9es avec volumes partag\u00e9s [\u2605\u2605]\n",
    "\n",
    "### Volumes partag\u00e9s pour la communication entre conteneurs\n",
    "\n",
    "Les volumes partag\u00e9s permettent aux conteneurs d'\u00e9changer des donn\u00e9es via le syst\u00e8me de fichiers.\n",
    "\n",
    "```\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    Uploader     \u2502       \u2502    Processeur   \u2502\n\u2502    Conteneur    \u2502       \u2502    Conteneur    \u2502\n\u2502                 \u2502       \u2502                 \u2502\n\u2502   \u00e9crit dans    \u2502       \u2502   lit depuis    \u2502\n\u2502   /shared       \u2502       \u2502   /shared       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502                         \u2502\n         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                   \u2502\n            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n            \u2502   Volume    \u2502\n            \u2502   Partag\u00e9   \u2502\n            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemple : Pipeline de traitement de fichiers\n",
    "\n",
    "Naviguez vers le dossier `SharedVolume` de ce TP :\n",
    "\n",
    "```bash\n",
    "cd SharedVolume\n",
    "```\n",
    "\n",
    "Examinez la structure existante :\n",
    "\n",
    "**Service Uploader** (`Uploader/upload.py`) :\n",
    "```python\n",
    "import time\n",
    "from shutil import copyfile\n",
    "\n",
    "def upload_file():\n",
    "    while True:\n",
    "        # Simule l'upload d'un nouveau fichier toutes les 5 secondes\n",
    "        print(\"Upload d'un nouveau fichier...\")\n",
    "        copyfile(\"sample.txt\", \"/shared/sample_uploaded.txt\")\n",
    "        time.sleep(5)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    upload_file()\n",
    "```\n",
    "\n",
    "**Service Processeur** (`Processor/process.py`) :\n",
    "```python\n",
    "import time\n",
    "import os\n",
    "\n",
    "def process_files():\n",
    "    while True:\n",
    "        if os.path.exists(\"/shared/sample_uploaded.txt\"):\n",
    "            with open(\"/shared/sample_uploaded.txt\", \"r\") as f:\n",
    "                content = f.read()\n",
    "            print(f\"Traitement : {content}\")\n",
    "            # Traiter le fichier...\n",
    "            os.remove(\"/shared/sample_uploaded.txt\")\n",
    "        else:\n",
    "            print(\"En attente de fichiers...\")\n",
    "        time.sleep(2)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_files()\n",
    "```\n",
    "\n",
    "**docker-compose.yml** :\n",
    "```yaml\n",
    "version: \"3.8\"\n",
    "\n",
    "services:\n",
    "  uploader:\n",
    "    build:\n",
    "      context: ./uploader\n",
    "    volumes:\n",
    "      - ./shared:/shared\n",
    "    depends_on:\n",
    "      - processor\n",
    "\n",
    "  processor:\n",
    "    build:\n",
    "      context: ./processor\n",
    "    volumes:\n",
    "      - ./shared:/shared\n",
    "```\n",
    "\n",
    "Ex\u00e9cutez avec :\n",
    "```bash\n",
    "docker-compose up --build\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemple de pipeline de donn\u00e9es am\u00e9lior\u00e9\n",
    "\n",
    "Cr\u00e9ez un pipeline de donn\u00e9es plus sophistiqu\u00e9 :\n",
    "\n",
    "**data_generator.py** :\n",
    "```python\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "def generate_data():\n",
    "    counter = 0\n",
    "    while True:\n",
    "        data = {\n",
    "            \"id\": counter,\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"sensor_id\": f\"capteur_{random.randint(1, 10)}\",\n",
    "            \"temperature\": round(random.uniform(20, 35), 2),\n",
    "            \"humidite\": round(random.uniform(30, 80), 2)\n",
    "        }\n",
    "        \n",
    "        filename = f\"/shared/input/data_{counter}.json\"\n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(data, f)\n",
    "        \n",
    "        print(f\"G\u00e9n\u00e9r\u00e9 : {filename}\")\n",
    "        counter += 1\n",
    "        time.sleep(2)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import os\n",
    "    os.makedirs(\"/shared/input\", exist_ok=True)\n",
    "    generate_data()\n",
    "```\n",
    "\n",
    "**data_processor.py** :\n",
    "```python\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "def process_files():\n",
    "    os.makedirs(\"/shared/output\", exist_ok=True)\n",
    "    \n",
    "    while True:\n",
    "        input_dir = \"/shared/input\"\n",
    "        if os.path.exists(input_dir):\n",
    "            files = [f for f in os.listdir(input_dir) if f.endswith('.json')]\n",
    "            \n",
    "            for filename in files:\n",
    "                filepath = os.path.join(input_dir, filename)\n",
    "                \n",
    "                with open(filepath, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                \n",
    "                # Traiter les donn\u00e9es\n",
    "                data['traite'] = True\n",
    "                data['temp_fahrenheit'] = round(data['temperature'] * 9/5 + 32, 2)\n",
    "                \n",
    "                # \u00c9crire dans le r\u00e9pertoire de sortie\n",
    "                output_path = f\"/shared/output/traite_{filename}\"\n",
    "                with open(output_path, 'w') as f:\n",
    "                    json.dump(data, f, indent=2)\n",
    "                \n",
    "                # Supprimer le fichier d'entr\u00e9e\n",
    "                os.remove(filepath)\n",
    "                print(f\"Trait\u00e9 : {filename}\")\n",
    "        \n",
    "        time.sleep(1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_files()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions - Exercice 4\n",
    "\n",
    "**Q4.1** \u00c9tendez l'exemple SharedVolume pour :\n",
    "- Ajouter un troisi\u00e8me service qui agr\u00e8ge les fichiers trait\u00e9s\n",
    "- G\u00e9n\u00e9rer des statistiques (temp\u00e9rature moyenne, humidit\u00e9 par capteur)\n",
    "- Produire un rapport de synth\u00e8se chaque minute\n",
    "\n",
    "**Q4.2** Impl\u00e9mentez la gestion des erreurs dans le pipeline :\n",
    "- D\u00e9placer les fichiers en \u00e9chec vers un r\u00e9pertoire \"erreur\"\n",
    "- Journaliser les erreurs avec des horodatages\n",
    "- Ajouter un service de surveillance qui rapporte l'\u00e9tat du pipeline\n",
    "\n",
    "**Q4.3** Cr\u00e9ez un pipeline de traitement parall\u00e8le :\n",
    "- Plusieurs conteneurs processeurs (utilisez `--scale`)\n",
    "- Impl\u00e9mentez le verrouillage de fichiers pour \u00e9viter le traitement en double\n",
    "- Mesurez le d\u00e9bit avec diff\u00e9rents nombres de processeurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercice 5 : Producteur-Consommateur avec files de messages [\u2605\u2605]\n",
    "\n",
    "### Mod\u00e8le de file de messages\n",
    "\n",
    "Les files de messages d\u00e9couplent les producteurs et consommateurs, permettant :\n",
    "- Le traitement asynchrone\n",
    "- L'\u00e9quilibrage de charge\n",
    "- La tol\u00e9rance aux pannes\n",
    "\n",
    "```\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502Producteur\u2502\u2500\u2500\u2500\u2500\u25ba\u2502   File de   \u2502\u2500\u2500\u2500\u2500\u25ba\u2502Consommat.\u2502\n\u2502    1     \u2502     \u2502   Messages  \u2502     \u2502    1     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2502  (RabbitMQ)\u2502     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u2502             \u2502     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502Producteur\u2502\u2500\u2500\u2500\u2500\u25ba\u2502             \u2502\u2500\u2500\u2500\u2500\u25ba\u2502Consommat.\u2502\n\u2502    2     \u2502     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2502    2     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemple RabbitMQ\n",
    "\n",
    "Naviguez vers le dossier `ProducerConsumerRabbitMQ` :\n",
    "\n",
    "```bash\n",
    "cd ProducerConsumerRabbitMQ\n",
    "```\n",
    "\n",
    "**producer/producer.py** :\n",
    "```python\n",
    "import pika\n",
    "import time\n",
    "\n",
    "def connect():\n",
    "    for i in range(5):\n",
    "        try:\n",
    "            return pika.BlockingConnection(pika.ConnectionParameters('rabbitmq'))\n",
    "        except:\n",
    "            print(\"Nouvelle tentative de connexion \u00e0 RabbitMQ...\")\n",
    "            time.sleep(2)\n",
    "    raise Exception(\"Impossible de se connecter \u00e0 RabbitMQ\")\n",
    "\n",
    "connection = connect()\n",
    "channel = connection.channel()\n",
    "channel.queue_declare(queue='task_queue', durable=True)\n",
    "\n",
    "for i in range(100):\n",
    "    msg = f\"T\u00e2che #{i}\"\n",
    "    channel.basic_publish(\n",
    "        exchange='',\n",
    "        routing_key='task_queue',\n",
    "        body=msg,\n",
    "        properties=pika.BasicProperties(delivery_mode=2)  # Rendre le message persistant\n",
    "    )\n",
    "    print(f\"Envoy\u00e9 : {msg}\")\n",
    "    time.sleep(1)\n",
    "\n",
    "connection.close()\n",
    "```\n",
    "\n",
    "**consumer/consumer.py** :\n",
    "```python\n",
    "import pika\n",
    "import time\n",
    "\n",
    "def connect():\n",
    "    for i in range(5):\n",
    "        try:\n",
    "            return pika.BlockingConnection(pika.ConnectionParameters('rabbitmq'))\n",
    "        except:\n",
    "            print(\"Nouvelle tentative de connexion \u00e0 RabbitMQ...\")\n",
    "            time.sleep(2)\n",
    "    raise Exception(\"Impossible de se connecter \u00e0 RabbitMQ\")\n",
    "\n",
    "def callback(ch, method, properties, body):\n",
    "    print(f\"Re\u00e7u : {body.decode()}\")\n",
    "    time.sleep(0.5)  # Simuler le traitement\n",
    "    print(f\"Trait\u00e9 : {body.decode()}\")\n",
    "    ch.basic_ack(delivery_tag=method.delivery_tag)\n",
    "\n",
    "connection = connect()\n",
    "channel = connection.channel()\n",
    "channel.queue_declare(queue='task_queue', durable=True)\n",
    "channel.basic_qos(prefetch_count=1)  # Distribution \u00e9quitable\n",
    "channel.basic_consume(queue='task_queue', on_message_callback=callback)\n",
    "\n",
    "print('En attente de messages...')\n",
    "channel.start_consuming()\n",
    "```\n",
    "\n",
    "**docker-compose.yml** :\n",
    "```yaml\n",
    "services:\n",
    "  rabbitmq:\n",
    "    image: rabbitmq:3-management\n",
    "    ports:\n",
    "      - \"5672:5672\"   # Protocole AMQP\n",
    "      - \"15672:15672\" # Interface de gestion\n",
    "    environment:\n",
    "      RABBITMQ_DEFAULT_USER: guest\n",
    "      RABBITMQ_DEFAULT_PASS: guest\n",
    "\n",
    "  producer:\n",
    "    build: ./producer\n",
    "    depends_on:\n",
    "      - rabbitmq\n",
    "\n",
    "  consumer:\n",
    "    build: ./consumer\n",
    "    depends_on:\n",
    "      - rabbitmq\n",
    "```\n",
    "\n",
    "Ex\u00e9cutez avec :\n",
    "```bash\n",
    "docker-compose up --build\n",
    "\n",
    "# Mettre \u00e0 l'\u00e9chelle les consommateurs\n",
    "docker-compose up --scale consumer=3\n",
    "```\n",
    "\n",
    "Acc\u00e9dez \u00e0 l'interface de gestion RabbitMQ : http://localhost:15672 (guest/guest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traitement de donn\u00e9es avec files de messages\n",
    "\n",
    "Producteur am\u00e9lior\u00e9 pour le traitement de donn\u00e9es :\n",
    "\n",
    "```python\n",
    "# data_producer.py\n",
    "import pika\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "def connect():\n",
    "    for i in range(5):\n",
    "        try:\n",
    "            return pika.BlockingConnection(pika.ConnectionParameters('rabbitmq'))\n",
    "        except:\n",
    "            time.sleep(2)\n",
    "    raise Exception(\"Impossible de se connecter\")\n",
    "\n",
    "connection = connect()\n",
    "channel = connection.channel()\n",
    "channel.queue_declare(queue='data_queue', durable=True)\n",
    "\n",
    "sensors = ['temperature', 'humidite', 'pression']\n",
    "\n",
    "while True:\n",
    "    data = {\n",
    "        'type_capteur': random.choice(sensors),\n",
    "        'valeur': round(random.uniform(0, 100), 2),\n",
    "        'timestamp': datetime.now().isoformat()\n",
    "    }\n",
    "    \n",
    "    channel.basic_publish(\n",
    "        exchange='',\n",
    "        routing_key='data_queue',\n",
    "        body=json.dumps(data),\n",
    "        properties=pika.BasicProperties(delivery_mode=2)\n",
    "    )\n",
    "    \n",
    "    print(f\"Envoy\u00e9 : {data}\")\n",
    "    time.sleep(0.5)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions - Exercice 5\n",
    "\n",
    "**Q5.1** \u00c9tendez l'exemple RabbitMQ pour :\n",
    "- Utiliser le routage par sujet (diff\u00e9rentes files pour diff\u00e9rents types de donn\u00e9es)\n",
    "- Impl\u00e9menter plusieurs types de consommateurs (un pour chaque type de capteur)\n",
    "- Stocker les donn\u00e9es trait\u00e9es dans un volume partag\u00e9\n",
    "\n",
    "**Q5.2** Impl\u00e9mentez la gestion des lettres mortes :\n",
    "- Configurez une file de lettres mortes pour les messages \u00e9chou\u00e9s\n",
    "- Ajoutez un m\u00e9canisme de nouvelle tentative (maximum 3 tentatives)\n",
    "- Cr\u00e9ez un consommateur de surveillance qui alerte sur les messages DLQ\n",
    "\n",
    "**Q5.3** Comparez RabbitMQ avec Redis Pub/Sub :\n",
    "- Impl\u00e9mentez le m\u00eame mod\u00e8le producteur-consommateur avec Redis\n",
    "- Mesurez le d\u00e9bit des messages\n",
    "- Documentez les compromis entre les deux approches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercice 6 : Int\u00e9gration Application-Base de donn\u00e9es [\u2605\u2605]\n",
    "\n",
    "### Connexion d'applications aux bases de donn\u00e9es\n",
    "\n",
    "Naviguez vers le dossier `AppDB` :\n",
    "\n",
    "```bash\n",
    "cd AppDB\n",
    "```\n",
    "\n",
    "Cet exemple d\u00e9montre une application Flask connect\u00e9e \u00e0 PostgreSQL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**app/app.py** :\n",
    "```python\n",
    "from flask import Flask\n",
    "import psycopg2\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route(\"/\")\n",
    "def index():\n",
    "    conn = psycopg2.connect(\n",
    "        host=\"bd\",  # Nom du service dans Docker\n",
    "        database=\"livres\",\n",
    "        user=\"postgres\",\n",
    "        password=\"postgres\"\n",
    "    )\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"SELECT titre FROM livres\")\n",
    "    livres = cur.fetchall()\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    return \"<br>\".join(title for (title,) in livres)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(host=\"0.0.0.0\", port=5000)\n",
    "```\n",
    "\n",
    "**init_bd/init.sql** :\n",
    "```sql\n",
    "CREATE TABLE IF NOT EXISTS livres (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    titre VARCHAR(255) NOT NULL,\n",
    "    auteur VARCHAR(255),\n",
    "    annee INTEGER\n",
    ");\n",
    "\n",
    "INSERT INTO livres (titre, auteur, annee) VALUES\n",
    "    ('Les Mis\u00e9rables', 'Victor Hugo', 1862),\n",
    "    ('Le Petit Prince', 'Antoine de Saint-Exup\u00e9ry', 1943),\n",
    "    ('L''\u00c9tranger', 'Albert Camus', 1942);\n",
    "```\n",
    "\n",
    "**docker-compose.yml** :\n",
    "```yaml\n",
    "services:\n",
    "  app:\n",
    "    build: ./app\n",
    "    ports:\n",
    "      - \"5000:5000\"\n",
    "    depends_on:\n",
    "      - bd\n",
    "\n",
    "  bd:\n",
    "    image: postgres:15\n",
    "    environment:\n",
    "      POSTGRES_DB: livres\n",
    "      POSTGRES_USER: postgres\n",
    "      POSTGRES_PASSWORD: postgres\n",
    "    volumes:\n",
    "      - ./init_bd:/docker-entrypoint-initdb.d\n",
    "      - postgres_data:/var/lib/postgresql/data\n",
    "    ports:\n",
    "      - \"5432:5432\"\n",
    "\n",
    "volumes:\n",
    "  postgres_data:\n",
    "```\n",
    "\n",
    "Ex\u00e9cutez avec :\n",
    "```bash\n",
    "docker-compose up --build\n",
    "```\n",
    "\n",
    "Acc\u00e9dez \u00e0 : http://localhost:5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemple am\u00e9lior\u00e9 avec SQLAlchemy\n",
    "\n",
    "```python\n",
    "# app_enhanced.py\n",
    "from flask import Flask, jsonify, request\n",
    "from flask_sqlalchemy import SQLAlchemy\n",
    "import os\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Configuration de la base de donn\u00e9es depuis l'environnement\n",
    "db_host = os.environ.get('DB_HOST', 'bd')\n",
    "db_name = os.environ.get('DB_NAME', 'livres')\n",
    "db_user = os.environ.get('DB_USER', 'postgres')\n",
    "db_pass = os.environ.get('DB_PASS', 'postgres')\n",
    "\n",
    "app.config['SQLALCHEMY_DATABASE_URI'] = f'postgresql://{db_user}:{db_pass}@{db_host}/{db_name}'\n",
    "app.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = False\n",
    "\n",
    "db = SQLAlchemy(app)\n",
    "\n",
    "class Book(db.Model):\n",
    "    __tablename__ = 'livres'\n",
    "    id = db.Column(db.Integer, primary_key=True)\n",
    "    titre = db.Column(db.String(255), nullable=False)\n",
    "    auteur = db.Column(db.String(255))\n",
    "    annee = db.Column(db.Integer)\n",
    "\n",
    "@app.route('/books')\n",
    "def get_books():\n",
    "    books = Book.query.all()\n",
    "    return jsonify([{\n",
    "        'id': b.id,\n",
    "        'titre': b.titre,\n",
    "        'auteur': b.auteur,\n",
    "        'annee': b.annee\n",
    "    } for b in books])\n",
    "\n",
    "@app.route('/books', methods=['POST'])\n",
    "def add_book():\n",
    "    data = request.json\n",
    "    book = Book(titre=data['titre'], auteur=data['auteur'], annee=data['annee'])\n",
    "    db.session.add(book)\n",
    "    db.session.commit()\n",
    "    return jsonify({'id': book.id}), 201\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5000)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions - Exercice 6\n",
    "\n",
    "**Q6.1** \u00c9tendez l'exemple AppDB pour inclure :\n",
    "- Op\u00e9rations CRUD (Cr\u00e9er, Lire, Mettre \u00e0 jour, Supprimer)\n",
    "- Validation des entr\u00e9es\n",
    "- Gestion des erreurs avec codes de statut HTTP appropri\u00e9s\n",
    "\n",
    "**Q6.2** Ajoutez des capacit\u00e9s d'analyse de donn\u00e9es :\n",
    "- Endpoint pour obtenir les livres par plage d'ann\u00e9es\n",
    "- Endpoint de statistiques (nombre par auteur, livres par d\u00e9cennie)\n",
    "- Capacit\u00e9 de recherche en texte int\u00e9gral\n",
    "\n",
    "**Q6.3** Impl\u00e9mentez un service d'importation de donn\u00e9es :\n",
    "- Cr\u00e9ez un conteneur s\u00e9par\u00e9 qui importe des donn\u00e9es CSV dans la base de donn\u00e9es\n",
    "- Surveillez un volume partag\u00e9 pour les nouveaux fichiers CSV\n",
    "- Journalisez les r\u00e9sultats et erreurs d'importation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercice 7 : Architectures Frontend-Backend [\u2605\u2605\u2605]\n",
    "\n",
    "### Architecture Microservices\n",
    "\n",
    "Naviguez vers le dossier `WebAppFrontBack` :\n",
    "\n",
    "```bash\n",
    "cd WebAppFrontBack\n",
    "```\n",
    "\n",
    "Cet exemple d\u00e9montre un frontend React avec un backend Flask.\n",
    "\n",
    "```\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    Frontend     \u2502      \u2502    Backend      \u2502\n\u2502    (React)      \u2502\u2500\u2500\u2500\u2500\u2500\u25ba\u2502    (Flask)      \u2502\n\u2502   Port: 3000   \u2502      \u2502   Port: 5000    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API Backend (Flask)\n",
    "\n",
    "**backend/app.py** :\n",
    "```python\n",
    "from flask import Flask, jsonify, request\n",
    "from flask_cors import CORS\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)  # Activer les requ\u00eates Cross-Origin\n",
    "\n",
    "# Stockage de donn\u00e9es en m\u00e9moire\n",
    "tasks = [\n",
    "    {\"id\": 1, \"title\": \"Apprendre Docker\", \"completed\": True},\n",
    "    {\"id\": 2, \"title\": \"Construire un pipeline\", \"completed\": False}\n",
    "]\n",
    "\n",
    "@app.route('/api/tasks', methods=['GET'])\n",
    "def get_tasks():\n",
    "    return jsonify(tasks)\n",
    "\n",
    "@app.route('/api/tasks', methods=['POST'])\n",
    "def add_task():\n",
    "    data = request.json\n",
    "    new_task = {\n",
    "        \"id\": len(tasks) + 1,\n",
    "        \"title\": data['title'],\n",
    "        \"completed\": False\n",
    "    }\n",
    "    tasks.append(new_task)\n",
    "    return jsonify(new_task), 201\n",
    "\n",
    "@app.route('/api/tasks/<int:task_id>', methods=['PUT'])\n",
    "def update_task(task_id):\n",
    "    task = next((t for t in tasks if t['id'] == task_id), None)\n",
    "    if task:\n",
    "        data = request.json\n",
    "        task['completed'] = data.get('completed', task['completed'])\n",
    "        return jsonify(task)\n",
    "    return jsonify({\"error\": \"T\u00e2che non trouv\u00e9e\"}), 404\n",
    "\n",
    "@app.route('/api/tasks/<int:task_id>', methods=['DELETE'])\n",
    "def delete_task(task_id):\n",
    "    global tasks\n",
    "    tasks = [t for t in tasks if t['id'] != task_id]\n",
    "    return '', 204\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5000)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Docker Compose pour Full Stack\n",
    "\n",
    "**docker-compose.yml** :\n",
    "```yaml\n",
    "version: \"3.8\"\n",
    "\n",
    "services:\n",
    "  frontend:\n",
    "    build:\n",
    "      context: ./frontend\n",
    "    ports:\n",
    "      - \"3000:3000\"\n",
    "    depends_on:\n",
    "      - backend\n",
    "    environment:\n",
    "      - REACT_APP_API_URL=http://localhost:5000\n",
    "\n",
    "  backend:\n",
    "    build:\n",
    "      context: ./backend\n",
    "    ports:\n",
    "      - \"5000:5000\"\n",
    "    volumes:\n",
    "      - ./backend:/app\n",
    "    environment:\n",
    "      - FLASK_ENV=development\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajout de Nginx comme Reverse Proxy\n",
    "\n",
    "Pour les d\u00e9ploiements en production, utilisez Nginx comme reverse proxy :\n",
    "\n",
    "**nginx.conf** :\n",
    "```nginx\n",
    "upstream frontend {\n",
    "    server frontend:3000;\n",
    "}\n",
    "\n",
    "upstream backend {\n",
    "    server backend:5000;\n",
    "}\n",
    "\n",
    "server {\n",
    "    listen 80;\n",
    "\n",
    "    location / {\n",
    "        proxy_pass http://frontend;\n",
    "        proxy_http_version 1.1;\n",
    "        proxy_set_header Upgrade $http_upgrade;\n",
    "        proxy_set_header Connection \"upgrade\";\n",
    "    }\n",
    "\n",
    "    location /api {\n",
    "        proxy_pass http://backend;\n",
    "        proxy_set_header Host $host;\n",
    "        proxy_set_header X-Real-IP $remote_addr;\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "**docker-compose.prod.yml** :\n",
    "```yaml\n",
    "version: \"3.8\"\n",
    "\n",
    "services:\n",
    "  nginx:\n",
    "    image: nginx:alpine\n",
    "    ports:\n",
    "      - \"80:80\"\n",
    "    volumes:\n",
    "      - ./nginx.conf:/etc/nginx/conf.d/default.conf\n",
    "    depends_on:\n",
    "      - frontend\n",
    "      - backend\n",
    "\n",
    "  frontend:\n",
    "    build:\n",
    "      context: ./frontend\n",
    "      dockerfile: Dockerfile.prod\n",
    "\n",
    "  backend:\n",
    "    build:\n",
    "      context: ./backend\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions - Exercice 7\n",
    "\n",
    "**Q7.1** \u00c9tendez l'exemple frontend-backend pour inclure :\n",
    "- Authentification utilisateur (connexion/d\u00e9connexion)\n",
    "- Routes prot\u00e9g\u00e9es\n",
    "- Gestion des tokens JWT\n",
    "\n",
    "**Q7.2** Ajoutez une base de donn\u00e9es \u00e0 la pile :\n",
    "- Remplacez le stockage en m\u00e9moire par PostgreSQL\n",
    "- Ajoutez des migrations de base de donn\u00e9es\n",
    "- Impl\u00e9mentez la persistance des donn\u00e9es entre les red\u00e9marrages\n",
    "\n",
    "**Q7.3** Cr\u00e9ez un tableau de bord de visualisation de donn\u00e9es :\n",
    "- API backend qui sert des donn\u00e9es d'analyse\n",
    "- Frontend avec des graphiques (utilisant Chart.js ou similaire)\n",
    "- Mises \u00e0 jour en temps r\u00e9el utilisant WebSockets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercice 8 : Mise \u00e0 l'\u00e9chelle et surveillance des conteneurs [\u2605\u2605\u2605]\n",
    "\n",
    "### Mise \u00e0 l'\u00e9chelle des conteneurs\n",
    "\n",
    "```bash\n",
    "# Mettre \u00e0 l'\u00e9chelle un service sp\u00e9cifique\n",
    "docker-compose up --scale worker=5\n",
    "\n",
    "# Afficher les conteneurs en cours d'ex\u00e9cution\n",
    "docker-compose ps\n",
    "\n",
    "# Afficher l'utilisation des ressources\n",
    "docker stats\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \u00c9quilibrage de charge avec Nginx\n",
    "\n",
    "**docker-compose.yml** :\n",
    "```yaml\n",
    "version: \"3.8\"\n",
    "\n",
    "services:\n",
    "  nginx:\n",
    "    image: nginx:alpine\n",
    "    ports:\n",
    "      - \"80:80\"\n",
    "    volumes:\n",
    "      - ./nginx.conf:/etc/nginx/nginx.conf:ro\n",
    "    depends_on:\n",
    "      - api\n",
    "\n",
    "  api:\n",
    "    build: .\n",
    "    # Pas de ports expos\u00e9s - acc\u00e8s via nginx\n",
    "    deploy:\n",
    "      replicas: 3\n",
    "```\n",
    "\n",
    "**nginx.conf** pour l'\u00e9quilibrage de charge :\n",
    "```nginx\n",
    "events {\n",
    "    worker_connections 1024;\n",
    "}\n",
    "\n",
    "http {\n",
    "    upstream api_servers {\n",
    "        least_conn;  # M\u00e9thode d'\u00e9quilibrage de charge\n",
    "        server api:5000;\n",
    "    }\n",
    "\n",
    "    server {\n",
    "        listen 80;\n",
    "\n",
    "        location / {\n",
    "            proxy_pass http://api_servers;\n",
    "            proxy_set_header Host $host;\n",
    "            proxy_set_header X-Real-IP $remote_addr;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Surveillance avec Prometheus et Grafana\n",
    "\n",
    "**docker-compose.monitoring.yml** :\n",
    "```yaml\n",
    "version: \"3.8\"\n",
    "\n",
    "services:\n",
    "  prometheus:\n",
    "    image: prom/prometheus\n",
    "    ports:\n",
    "      - \"9090:9090\"\n",
    "    volumes:\n",
    "      - ./prometheus.yml:/etc/prometheus/prometheus.yml\n",
    "      - prometheus_data:/prometheus\n",
    "\n",
    "  grafana:\n",
    "    image: grafana/grafana\n",
    "    ports:\n",
    "      - \"3000:3000\"\n",
    "    volumes:\n",
    "      - grafana_data:/var/lib/grafana\n",
    "    environment:\n",
    "      - GF_SECURITY_ADMIN_PASSWORD=admin\n",
    "\n",
    "  cadvisor:\n",
    "    image: gcr.io/cadvisor/cadvisor\n",
    "    ports:\n",
    "      - \"8080:8080\"\n",
    "    volumes:\n",
    "      - /:/rootfs:ro\n",
    "      - /var/run:/var/run:ro\n",
    "      - /sys:/sys:ro\n",
    "      - /var/lib/docker/:/var/lib/docker:ro\n",
    "\n",
    "volumes:\n",
    "  prometheus_data:\n",
    "  grafana_data:\n",
    "```\n",
    "\n",
    "**prometheus.yml** :\n",
    "```yaml\n",
    "global:\n",
    "  scrape_interval: 15s\n",
    "\n",
    "scrape_configs:\n",
    "  - job_name: 'prometheus'\n",
    "    static_configs:\n",
    "      - targets: ['localhost:9090']\n",
    "\n",
    "  - job_name: 'cadvisor'\n",
    "    static_configs:\n",
    "      - targets: ['cadvisor:8080']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limites de ressources\n",
    "\n",
    "```yaml\n",
    "version: \"3.8\"\n",
    "\n",
    "services:\n",
    "  api:\n",
    "    build: .\n",
    "    deploy:\n",
    "      resources:\n",
    "        limits:\n",
    "          cpus: '0.50'\n",
    "          memory: 512M\n",
    "        reservations:\n",
    "          cpus: '0.25'\n",
    "          memory: 256M\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions - Exercice 8\n",
    "\n",
    "**Q8.1** Cr\u00e9ez un pipeline de traitement de donn\u00e9es \u00e9volutif :\n",
    "- Service producteur g\u00e9n\u00e9rant des donn\u00e9es\n",
    "- Services workers pouvant \u00eatre mis \u00e0 l'\u00e9chelle (1-10 instances)\n",
    "- \u00c9quilibreur de charge distribuant le travail\n",
    "- Mesurez le d\u00e9bit avec diff\u00e9rents nombres de workers\n",
    "\n",
    "**Q8.2** Configurez la surveillance pour votre application :\n",
    "- Configurez Prometheus pour collecter les m\u00e9triques\n",
    "- Cr\u00e9ez des tableaux de bord Grafana pour :\n",
    "  - Utilisation CPU et m\u00e9moire\n",
    "  - Taux de requ\u00eates et latences\n",
    "  - Taux d'erreurs\n",
    "\n",
    "**Q8.3** Impl\u00e9mentez une simulation d'auto-scaling :\n",
    "- Surveillez l'utilisation CPU des conteneurs workers\n",
    "- Cr\u00e9ez un script qui met \u00e0 l'\u00e9chelle les workers en fonction de la charge\n",
    "- Testez avec diff\u00e9rents mod\u00e8les de charge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## R\u00e9sum\u00e9\n",
    "\n",
    "Dans ce TP, vous avez appris :\n",
    "\n",
    "1. **Fondamentaux Docker** : Images, conteneurs et commandes de base\n",
    "2. **Dockerfiles** : \u00c9criture de Dockerfiles efficaces pour applications Python\n",
    "3. **Docker Compose** : Orchestration d'applications multi-conteneurs\n",
    "4. **Volumes partag\u00e9s** : Construction de pipelines de donn\u00e9es avec communication par fichiers\n",
    "5. **Files de messages** : Mod\u00e8les producteur-consommateur avec RabbitMQ\n",
    "6. **Int\u00e9gration de base de donn\u00e9es** : Connexion d'applications \u00e0 PostgreSQL\n",
    "7. **Frontend-Backend** : Construction d'applications full-stack\n",
    "8. **Mise \u00e0 l'\u00e9chelle et surveillance** : \u00c9quilibrage de charge et observabilit\u00e9\n",
    "\n",
    "### Points cl\u00e9s \u00e0 retenir\n",
    "\n",
    "- Utilisez Docker Compose pour le d\u00e9veloppement et les tests\n",
    "- Impl\u00e9mentez des v\u00e9rifications de sant\u00e9 correctes pour les d\u00e9pendances de services\n",
    "- Utilisez des volumes pour la persistance des donn\u00e9es\n",
    "- Choisissez le bon mod\u00e8le de communication (fichiers, messages, API)\n",
    "- Surveillez et mettez \u00e0 l'\u00e9chelle en fonction des m\u00e9triques\n",
    "\n",
    "### Prochaines \u00e9tapes\n",
    "\n",
    "Dans le TP 7, vous apprendrez Kubernetes pour :\n",
    "- L'orchestration de conteneurs de niveau production\n",
    "- La gestion de configuration d\u00e9clarative\n",
    "- La mise \u00e0 l'\u00e9chelle automatique et l'auto-r\u00e9paration\n",
    "- La d\u00e9couverte de services et l'\u00e9quilibrage de charge\n",
    "\n",
    "### Lectures compl\u00e9mentaires\n",
    "\n",
    "- [Documentation Docker](https://docs.docker.com/)\n",
    "- [Documentation Docker Compose](https://docs.docker.com/compose/)\n",
    "- [Bonnes pratiques pour l'\u00e9criture de Dockerfiles](https://docs.docker.com/develop/develop-images/dockerfile_best-practices/)\n",
    "- [Bonnes pratiques de s\u00e9curit\u00e9 Docker](https://docs.docker.com/develop/security-best-practices/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP 4 : Fondamentaux du Calcul Parallèle et Distribué\n",
    "\n",
    "## Objectifs\n",
    "\n",
    "### Comprendre les paradigmes du calcul parallèle\n",
    "- Exécution séquentielle vs parallèle\n",
    "- Concurrence vs parallélisme\n",
    "- Loi d'Amdahl et calculs d'accélération\n",
    "\n",
    "### Maîtriser la programmation fonctionnelle en Python\n",
    "- `filter()`, `map()`, `reduce()` avec expressions lambda\n",
    "- Générateurs et itérateurs pour un traitement efficace en mémoire\n",
    "\n",
    "### Implémenter le traitement parallèle\n",
    "- Module `multiprocessing` (Process, Pool, Queue, Pipe)\n",
    "- `concurrent.futures` (ThreadPoolExecutor, ProcessPoolExecutor)\n",
    "- Mémoire partagée et primitives de synchronisation\n",
    "\n",
    "### Mesure et optimisation des performances\n",
    "- Benchmarking du code parallèle\n",
    "- Identification des goulots d'étranglement\n",
    "- Stratégies de découpage (chunking)\n",
    "\n",
    "## Prérequis\n",
    "\n",
    "- Achèvement des TP 0-3\n",
    "- Compréhension des fonctions et structures de données Python\n",
    "- Connaissances de base de l'architecture informatique (cœurs CPU)\n",
    "\n",
    "## Aperçu des exercices\n",
    "\n",
    "| Exercice | Difficulté | Sujets |\n",
    "|----------|------------|--------|\n",
    "| Exercice 1 | ★ | Programmation fonctionnelle : filter(), map(), reduce() |\n",
    "| Exercice 2 | ★ | Expressions lambda et fonctions d'ordre supérieur |\n",
    "| Exercice 3 | ★★ | Générateurs et itérateurs pour les grandes données |\n",
    "| Exercice 4 | ★★ | Introduction au multiprocessing |\n",
    "| Exercice 5 | ★★ | Communication inter-processus : Queues et Pipes |\n",
    "| Exercice 6 | ★★★ | concurrent.futures et modèles asynchrones |\n",
    "| Exercice 7 | ★★★ | Benchmarking et optimisation des performances |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 1 [★] - Programmation fonctionnelle : filter(), map(), reduce()\n",
    "\n",
    "Dans cet exercice, nous explorons les concepts de programmation fonctionnelle qui forment la base du traitement de données parallèle et distribué. Ces modèles sont utilisés intensivement dans des frameworks comme Apache Spark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Introduction à la programmation fonctionnelle\n",
    "\n",
    "La programmation fonctionnelle met l'accent sur :\n",
    "- **Fonctions pures** : Fonctions qui produisent toujours le même résultat pour la même entrée et n'ont pas d'effets de bord\n",
    "- **Immutabilité** : Les données ne sont pas modifiées après leur création\n",
    "- **Fonctions de première classe** : Les fonctions peuvent être passées en arguments et retournées par d'autres fonctions\n",
    "\n",
    "Ces principes sont essentiels pour le traitement parallèle car ils éliminent l'état partagé et rendent sûre l'exécution concurrente des opérations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. La fonction filter()\n",
    "\n",
    "La fonction `filter(function, iterable)` retourne un itérateur contenant les éléments de l'itérable pour lesquels la fonction retourne `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple basique de filter : filtrer les nombres pairs\n",
    "num = [i for i in range(1, 20)]\n",
    "print(\"Liste originale :\", num)\n",
    "\n",
    "def est_pair(item):\n",
    "    return item % 2 == 0\n",
    "\n",
    "filtre = list(filter(est_pair, num))\n",
    "print(\"Nombres pairs :\", filtre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter avec None comme fonction - supprime les valeurs fausses (falsy)\n",
    "mixte = [0, 1, \"\", \"bonjour\", None, 42, [], [1, 2]]\n",
    "print(\"Original :\", mixte)\n",
    "print(\"Filtré (uniquement truthy) :\", list(filter(None, mixte)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrer les nombres impairs\n",
    "def est_impair(item):\n",
    "    return item % 2 != 0\n",
    "\n",
    "num = [i for i in range(1, 20)]\n",
    "filtre = list(filter(est_impair, num))\n",
    "print(\"Nombres impairs :\", filtre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.1** : Écrivez une fonction `est_premier(n)` qui retourne `True` si `n` est un nombre premier. Ensuite, utilisez `filter()` pour extraire tous les nombres premiers d'une liste de 1000 entiers aléatoires entre 1 et 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Générer 1000 entiers aléatoires\n",
    "nombres_aleatoires = [random.randint(1, 1000) for _ in range(1000)]\n",
    "\n",
    "# TODO: Implémenter la fonction est_premier et filtrer les nombres premiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.2** : Utilisez `filter()` pour extraire les nombres divisibles à la fois par 3 et par 5 de la même liste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Filtrer les nombres divisibles par 3 et 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtrage avec des structures imbriquées\n",
    "\n",
    "La fonction `filter()` peut être appliquée à des structures de données complexes comme des listes de dictionnaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employes = [\n",
    "    {\"nom\": \"Alice\", \"age\": 28, \"departement\": \"RH\", \"salaire\": 55000},\n",
    "    {\"nom\": \"Bob\", \"age\": 35, \"departement\": \"Ingénierie\", \"salaire\": 85000},\n",
    "    {\"nom\": \"Charlie\", \"age\": 22, \"departement\": \"Marketing\", \"salaire\": 45000},\n",
    "    {\"nom\": \"David\", \"age\": 45, \"departement\": \"Ingénierie\", \"salaire\": 95000},\n",
    "    {\"nom\": \"Eve\", \"age\": 31, \"departement\": \"RH\", \"salaire\": 60000},\n",
    "    {\"nom\": \"Frank\", \"age\": 29, \"departement\": \"Ingénierie\", \"salaire\": 78000},\n",
    "    {\"nom\": \"Grace\", \"age\": 38, \"departement\": \"Marketing\", \"salaire\": 72000},\n",
    "    {\"nom\": \"Henry\", \"age\": 42, \"departement\": \"Ingénierie\", \"salaire\": 92000}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.3** : En utilisant `filter()`, complétez les tâches suivantes :\n",
    "1. Créer une liste des employés qui travaillent dans le département \"Ingénierie\"\n",
    "2. Trouver les employés dont l'âge est entre 25 et 40 ans (inclus)\n",
    "3. Trouver les employés avec un salaire supérieur à 70000\n",
    "4. Trouver les employés dont le nom commence par une voyelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implémenter les filtres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtrage avancé de chaînes de caractères"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = [\n",
    "    \"La science des données transforme les industries dans le monde entier.\",\n",
    "    \"Python est génial.\",\n",
    "    \"Les algorithmes d'apprentissage automatique nécessitent de grandes quantités de données.\",\n",
    "    \"Les technologies Big Data permettent le traitement de pétaoctets.\",\n",
    "    \"L'IA évolue.\",\n",
    "    \"Le calcul distribué permet la mise à l'échelle horizontale sur les clusters.\",\n",
    "    \"Le cloud fournit des ressources informatiques élastiques à la demande.\",\n",
    "    \"Simple fonctionne.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.4** : En utilisant `filter()` :\n",
    "1. Sélectionner les phrases avec plus de 6 mots\n",
    "2. Sélectionner les phrases contenant le mot \"données\" (insensible à la casse)\n",
    "3. Sélectionner les phrases où la longueur moyenne des mots est supérieure à 5 caractères"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implémenter les filtres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. La fonction map()\n",
    "\n",
    "La fonction `map(function, iterable, ...)` applique une fonction à chaque élément d'un itérable et retourne un itérateur des résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple basique de map : mettre au carré chaque nombre\n",
    "def carre(x):\n",
    "    return x * x\n",
    "\n",
    "num = [i for i in range(1, 11)]\n",
    "carres = list(map(carre, num))\n",
    "print(\"Original :\", num)\n",
    "print(\"Carrés :\", carres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map avec plusieurs itérables\n",
    "def multiplier(x, y):\n",
    "    return x * y\n",
    "\n",
    "liste1 = [1, 2, 3, 4, 5]\n",
    "liste2 = [10, 20, 30, 40, 50]\n",
    "\n",
    "produits = list(map(multiplier, liste1, liste2))\n",
    "print(\"Produits :\", produits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map avec trois itérables\n",
    "def somme_ponderee(a, b, c):\n",
    "    return a + 2*b + 3*c\n",
    "\n",
    "x = [1, 2, 3]\n",
    "y = [4, 5, 6]\n",
    "z = [7, 8, 9]\n",
    "\n",
    "resultat = list(map(somme_ponderee, x, y, z))\n",
    "print(\"Sommes pondérées :\", resultat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.5** : Étant donné une liste de 100 000 chemins de fichiers, utilisez `map()` pour :\n",
    "1. Extraire les extensions de fichiers (ex : `.txt`, `.csv`)\n",
    "2. Extraire les noms de fichiers sans extensions\n",
    "3. Calculer les profondeurs de chemin (nombre de répertoires)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "# Générer des chemins de fichiers exemples\n",
    "extensions = ['.txt', '.csv', '.json', '.xml', '.py', '.md']\n",
    "repertoires = ['data', 'src', 'docs', 'config', 'tests', 'output']\n",
    "\n",
    "chemins_fichiers = [\n",
    "    os.path.join(\n",
    "        random.choice(repertoires),\n",
    "        random.choice(repertoires),\n",
    "        f\"fichier_{i}{random.choice(extensions)}\"\n",
    "    )\n",
    "    for i in range(100000)\n",
    "]\n",
    "\n",
    "print(\"Exemples de chemins :\", chemins_fichiers[:5])\n",
    "\n",
    "# TODO: Utiliser map() pour extraire les extensions, noms et calculer les profondeurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.6** : Utilisez `map()` pour normaliser un ensemble de 50 000 chaînes de texte :\n",
    "- Convertir en minuscules\n",
    "- Supprimer les espaces en début et fin\n",
    "- Supprimer la ponctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "# Générer des données textuelles exemples\n",
    "mots_exemples = [\"Bonjour\", \"Monde\", \"Données\", \"Science\", \"Python\", \"Analyse\"]\n",
    "signes_ponctuation = list(\"!.,;:?\")\n",
    "\n",
    "donnees_texte = [\n",
    "    f\"  {random.choice(mots_exemples)}{random.choice(signes_ponctuation)}  \".upper()\n",
    "    if random.random() > 0.5 else\n",
    "    f\"{random.choice(mots_exemples)} {random.choice(mots_exemples)}{random.choice(signes_ponctuation)}\"\n",
    "    for _ in range(50000)\n",
    "]\n",
    "\n",
    "print(\"Données exemples :\", donnees_texte[:5])\n",
    "\n",
    "# TODO: Utiliser map() pour normaliser les données textuelles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. La fonction reduce()\n",
    "\n",
    "La fonction `reduce(function, iterable)` applique une fonction de deux arguments de manière cumulative aux éléments d'un itérable, de gauche à droite, le réduisant à une seule valeur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "?reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Somme de nombres avec reduce\n",
    "from functools import reduce\n",
    "\n",
    "def addition(x, y):\n",
    "    return x + y\n",
    "\n",
    "num = [i for i in range(1, 11)]\n",
    "total = reduce(addition, num)\n",
    "print(f\"Somme de {num} = {total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produit de nombres\n",
    "def multiplier(x, y):\n",
    "    return x * y\n",
    "\n",
    "num = [1, 2, 3, 4, 5]\n",
    "produit = reduce(multiplier, num)\n",
    "print(f\"Produit de {num} = {produit}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trouver le maximum avec reduce\n",
    "def max_de_deux(x, y):\n",
    "    return x if x > y else y\n",
    "\n",
    "num = [45, 12, 89, 34, 67, 23, 90, 11]\n",
    "maximum = reduce(max_de_deux, num)\n",
    "print(f\"Maximum de {num} = {maximum}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.7** : Utilisez `reduce()` pour :\n",
    "1. Trouver la chaîne la plus longue dans une liste de 10 000 chaînes\n",
    "2. Aplatir une liste imbriquée (3 niveaux de profondeur)\n",
    "3. Concaténer une liste de chaînes avec un séparateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Générer des données exemples\n",
    "mots = [\"algorithme\", \"données\", \"traitement\", \"distribué\", \"calcul\", \n",
    "        \"parallèle\", \"optimisation\", \"scalabilité\", \"performance\"]\n",
    "\n",
    "liste_chaines = [random.choice(mots) * random.randint(1, 5) for _ in range(10000)]\n",
    "\n",
    "liste_imbriquee = [\n",
    "    [[1, 2], [3, 4]],\n",
    "    [[5, 6], [7, 8]],\n",
    "    [[9, 10], [11, 12]]\n",
    "]\n",
    "\n",
    "# TODO: Implémenter les opérations reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Opérations matricielles avec map() et reduce()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrices = [\n",
    "    [[1, 2], [3, 4]],\n",
    "    [[5, 6], [7, 8]],\n",
    "    [[9, 10], [11, 12]],\n",
    "    [[13, 14], [15, 16]]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.8** : En utilisant `map()` et `reduce()` :\n",
    "1. Calculer la somme de toutes les matrices\n",
    "2. Calculer le produit élément par élément de deux matrices\n",
    "3. Filtrer les matrices où tous les éléments sont supérieurs à 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implémenter les opérations matricielles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformation et agrégation de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "produits = [\n",
    "    {\"nom\": \"Ordinateur portable\", \"prix\": 1200, \"quantite\": 3, \"categorie\": \"Électronique\"},\n",
    "    {\"nom\": \"Smartphone\", \"prix\": 800, \"quantite\": 5, \"categorie\": \"Électronique\"},\n",
    "    {\"nom\": \"Tablette\", \"prix\": 300, \"quantite\": 10, \"categorie\": \"Électronique\"},\n",
    "    {\"nom\": \"Bureau\", \"prix\": 250, \"quantite\": 8, \"categorie\": \"Mobilier\"},\n",
    "    {\"nom\": \"Chaise\", \"prix\": 150, \"quantite\": 20, \"categorie\": \"Mobilier\"},\n",
    "    {\"nom\": \"Moniteur\", \"prix\": 350, \"quantite\": 7, \"categorie\": \"Électronique\"},\n",
    "    {\"nom\": \"Clavier\", \"prix\": 75, \"quantite\": 25, \"categorie\": \"Électronique\"},\n",
    "    {\"nom\": \"Bibliothèque\", \"prix\": 180, \"quantite\": 5, \"categorie\": \"Mobilier\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.9** : En utilisant `map()`, `filter()` et `reduce()` :\n",
    "1. Calculer la valeur totale de l'inventaire (prix * quantité pour tous les produits)\n",
    "2. Trouver les produits avec un prix supérieur à 200\n",
    "3. Appliquer une remise de 15% à tous les produits Électronique et retourner la liste mise à jour\n",
    "4. Calculer la valeur totale par catégorie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implémenter les opérations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 2 [★] - Expressions Lambda et Fonctions d'Ordre Supérieur\n",
    "\n",
    "Les expressions lambda sont des fonctions anonymes qui peuvent être définies en ligne. Elles sont particulièrement utiles avec `filter()`, `map()` et `reduce()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Bases des expressions lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lambda avec filter\n",
    "num = list(range(1, 21))\n",
    "pairs = list(filter(lambda x: x % 2 == 0, num))\n",
    "print(\"Nombres pairs :\", pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lambda avec map\n",
    "carres = list(map(lambda x: x ** 2, num))\n",
    "print(\"Carrés :\", carres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lambda avec plusieurs arguments\n",
    "liste1 = [1, 2, 3, 4, 5]\n",
    "liste2 = [10, 20, 30, 40, 50]\n",
    "produits = list(map(lambda x, y: x * y, liste1, liste2))\n",
    "print(\"Produits :\", produits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lambda avec reduce\n",
    "from functools import reduce\n",
    "\n",
    "total = reduce(lambda x, y: x + y, num)\n",
    "print(f\"Somme : {total}\")\n",
    "\n",
    "produit = reduce(lambda x, y: x * y, [1, 2, 3, 4, 5])\n",
    "print(f\"Produit : {produit}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Fonctions d'ordre supérieur et fermetures (closures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Une fermeture - fonction qui mémorise les valeurs de la portée englobante\n",
    "def creer_multiplicateur(n):\n",
    "    def multiplicateur(x):\n",
    "        return x * n\n",
    "    return multiplicateur\n",
    "\n",
    "double = creer_multiplicateur(2)\n",
    "triple = creer_multiplicateur(3)\n",
    "\n",
    "print(\"Double de 5 :\", double(5))\n",
    "print(\"Triple de 5 :\", triple(5))\n",
    "\n",
    "# Utilisation avec map\n",
    "nombres = [1, 2, 3, 4, 5]\n",
    "print(\"Doublés :\", list(map(double, nombres)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilisation de functools.partial pour l'application partielle de fonctions\n",
    "from functools import partial\n",
    "\n",
    "def puissance(base, exposant):\n",
    "    return base ** exposant\n",
    "\n",
    "carre = partial(puissance, exposant=2)\n",
    "cube = partial(puissance, exposant=3)\n",
    "\n",
    "print(\"Carré de 5 :\", carre(5))\n",
    "print(\"Cube de 5 :\", cube(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.1** : Créez une fonction fabrique de filtres qui génère des prédicats de filtre :\n",
    "1. `creer_filtre_plage(val_min, val_max)` - retourne une fonction qui vérifie si une valeur est dans la plage\n",
    "2. `creer_filtre_seuil(seuil, comparaison)` - retourne une fonction pour les comparaisons de seuil\n",
    "3. Utilisez-les avec `filter()` sur un jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implémenter les fonctions fabriques de filtres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Composition de fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Composer des fonctions : f(g(x))\n",
    "def composer(f, g):\n",
    "    return lambda x: f(g(x))\n",
    "\n",
    "def ajouter_un(x):\n",
    "    return x + 1\n",
    "\n",
    "def carre(x):\n",
    "    return x * x\n",
    "\n",
    "# (x + 1)^2\n",
    "ajouter_puis_carre = composer(carre, ajouter_un)\n",
    "print(\"(3 + 1)^2 =\", ajouter_puis_carre(3))\n",
    "\n",
    "# x^2 + 1\n",
    "carre_puis_ajouter = composer(ajouter_un, carre)\n",
    "print(\"3^2 + 1 =\", carre_puis_ajouter(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.2** : Implémentez une fonction `pipeline()` qui compose plusieurs fonctions et utilisez-la pour créer un pipeline de nettoyage de données :\n",
    "1. Supprimer les espaces\n",
    "2. Convertir en minuscules\n",
    "3. Supprimer les caractères spéciaux\n",
    "4. Remplacer les espaces multiples par un seul espace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implémenter la fonction pipeline et le pipeline de nettoyage de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyse de texte avec expressions lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = [\n",
    "    \"L'analyse de Big Data transforme les données brutes en insights actionnables.\",\n",
    "    \"Le cloud computing permet une infrastructure évolutive.\",\n",
    "    \"Les modèles d'apprentissage automatique nécessitent un entraînement sur de grands ensembles de données.\",\n",
    "    \"Les pipelines de données automatisent le flux d'information.\",\n",
    "    \"Les systèmes distribués offrent la tolérance aux pannes et la haute disponibilité.\",\n",
    "    \"Le traitement en temps réel gère efficacement les flux de données.\",\n",
    "    \"La gouvernance des données assure la qualité et la conformité.\",\n",
    "    \"Les API permettent une intégration transparente entre les services.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.3** : En utilisant `map()`, `filter()`, `reduce()` avec des expressions lambda :\n",
    "1. Compter le nombre total de mots dans toutes les phrases\n",
    "2. Trouver la phrase avec le plus de mots\n",
    "3. Extraire tous les mots uniques de toutes les phrases\n",
    "4. Calculer la longueur moyenne des phrases (en mots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implémenter l'analyse de texte avec lambdas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Traitement de données financières"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = [\n",
    "    {\"date\": \"2025-01-10\", \"type\": \"revenu\", \"montant\": 5000, \"categorie\": \"salaire\"},\n",
    "    {\"date\": \"2025-01-11\", \"type\": \"depense\", \"montant\": 150, \"categorie\": \"services\"},\n",
    "    {\"date\": \"2025-01-12\", \"type\": \"depense\", \"montant\": 80, \"categorie\": \"alimentation\"},\n",
    "    {\"date\": \"2025-01-13\", \"type\": \"revenu\", \"montant\": 200, \"categorie\": \"freelance\"},\n",
    "    {\"date\": \"2025-01-14\", \"type\": \"depense\", \"montant\": 500, \"categorie\": \"loyer\"},\n",
    "    {\"date\": \"2025-01-15\", \"type\": \"depense\", \"montant\": 60, \"categorie\": \"transport\"},\n",
    "    {\"date\": \"2025-01-16\", \"type\": \"revenu\", \"montant\": 150, \"categorie\": \"freelance\"},\n",
    "    {\"date\": \"2025-01-17\", \"type\": \"depense\", \"montant\": 200, \"categorie\": \"alimentation\"},\n",
    "    {\"date\": \"2025-01-18\", \"type\": \"depense\", \"montant\": 100, \"categorie\": \"loisirs\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.4** : En utilisant des expressions lambda :\n",
    "1. Calculer le solde net (total revenus - total dépenses)\n",
    "2. Trouver toutes les dépenses supérieures à 100\n",
    "3. Grouper les transactions par catégorie et calculer les totaux\n",
    "4. Trouver la plus grande dépense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implémenter le traitement des données financières"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 3 [★★] - Générateurs et Itérateurs pour les Grandes Données\n",
    "\n",
    "Lors du traitement de jeux de données massifs, charger tout en mémoire est souvent impossible. Les générateurs fournissent un moyen efficace en mémoire de traiter les données de manière paresseuse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Bases des générateurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compréhension de liste vs expression génératrice\n",
    "import sys\n",
    "\n",
    "# Liste - stocke toutes les valeurs en mémoire\n",
    "comp_liste = [x ** 2 for x in range(1000000)]\n",
    "print(f\"Taille de la liste : {sys.getsizeof(comp_liste):,} octets\")\n",
    "\n",
    "# Générateur - calcule les valeurs à la demande\n",
    "exp_gen = (x ** 2 for x in range(1000000))\n",
    "print(f\"Taille du générateur : {sys.getsizeof(exp_gen):,} octets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction génératrice utilisant yield\n",
    "def compter_jusqua(n):\n",
    "    \"\"\"Générateur qui yield les nombres de 1 à n\"\"\"\n",
    "    i = 1\n",
    "    while i <= n:\n",
    "        yield i\n",
    "        i += 1\n",
    "\n",
    "# Utilisation du générateur\n",
    "compteur = compter_jusqua(5)\n",
    "print(\"Type :\", type(compteur))\n",
    "print(\"Valeurs :\", list(compteur))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les générateurs ne peuvent être itérés qu'une seule fois\n",
    "gen = (x for x in range(5))\n",
    "print(\"Première itération :\", list(gen))\n",
    "print(\"Deuxième itération :\", list(gen))  # Vide !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.1** : Créez une fonction génératrice `lire_gros_fichier(chemin, taille_chunk)` qui :\n",
    "1. Lit un fichier par morceaux de `taille_chunk` lignes\n",
    "2. Yield chaque morceau sous forme de liste de lignes\n",
    "3. Ne charge jamais le fichier entier en mémoire\n",
    "\n",
    "Testez avec un fichier contenant des millions de lignes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "fichier_test = \"gros_fichier_test.txt\"\n",
    "with open(fichier_test, 'w') as f:\n",
    "    for i in range(100000):\n",
    "        f.write(f\"Ligne {i}: Ceci est une donnée de test pour l'exercice générateur\\n\")\n",
    "\n",
    "print(f\"Fichier créé avec taille : {os.path.getsize(fichier_test):,} octets\")\n",
    "\n",
    "# TODO: Implémenter le générateur lire_gros_fichier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Pipelines de générateurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chaîner des générateurs crée un pipeline\n",
    "def lire_lignes(nom_fichier):\n",
    "    \"\"\"Générateur qui yield les lignes d'un fichier\"\"\"\n",
    "    with open(nom_fichier, 'r') as f:\n",
    "        for ligne in f:\n",
    "            yield ligne.strip()\n",
    "\n",
    "def filtrer_non_vides(lignes):\n",
    "    \"\"\"Générateur qui yield les lignes non vides\"\"\"\n",
    "    for ligne in lignes:\n",
    "        if ligne:\n",
    "            yield ligne\n",
    "\n",
    "def extraire_numeros(lignes):\n",
    "    \"\"\"Générateur qui extrait le numéro de ligne\"\"\"\n",
    "    for ligne in lignes:\n",
    "        parties = ligne.split(':')\n",
    "        if len(parties) >= 1:\n",
    "            partie_num = parties[0].replace('Ligne ', '')\n",
    "            if partie_num.isdigit():\n",
    "                yield int(partie_num)\n",
    "\n",
    "# Pipeline: lire -> filtrer -> extraire -> sommer\n",
    "pipeline = extraire_numeros(filtrer_non_vides(lire_lignes(fichier_test)))\n",
    "\n",
    "# Traiter les 100 premiers nombres\n",
    "from itertools import islice\n",
    "premiers_100 = list(islice(pipeline, 100))\n",
    "print(f\"10 premiers numéros de ligne : {premiers_100[:10]}\")\n",
    "print(f\"Somme des 100 premiers : {sum(premiers_100)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.2** : Créez un pipeline de générateurs pour l'analyse de fichiers log :\n",
    "1. `lire_logs(chemin)` - yield les entrées de log\n",
    "2. `analyser_logs(logs)` - analyse chaque log en dictionnaire avec timestamp, niveau, message\n",
    "3. `filtrer_erreurs(logs)` - yield uniquement les logs de niveau ERROR\n",
    "4. `extraire_messages(logs)` - yield uniquement le champ message\n",
    "\n",
    "Utilisez le pipeline pour traiter un gros fichier log sans le charger entièrement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un fichier log exemple\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "fichier_log = \"logs_exemples.txt\"\n",
    "niveaux = [\"INFO\", \"DEBUG\", \"WARNING\", \"ERROR\", \"INFO\", \"INFO\", \"DEBUG\"]\n",
    "messages = [\n",
    "    \"Connexion établie\",\n",
    "    \"Traitement de la requête\",\n",
    "    \"Requête base de données exécutée\",\n",
    "    \"Échec de connexion au serveur\",\n",
    "    \"Timeout survenu\",\n",
    "    \"Cache miss\",\n",
    "    \"Utilisateur authentifié\",\n",
    "    \"Entrée invalide reçue\"\n",
    "]\n",
    "\n",
    "temps_base = datetime.now()\n",
    "with open(fichier_log, 'w') as f:\n",
    "    for i in range(50000):\n",
    "        timestamp = (temps_base + timedelta(seconds=i)).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        niveau = random.choice(niveaux)\n",
    "        message = random.choice(messages)\n",
    "        f.write(f\"{timestamp} [{niveau}] {message}\\n\")\n",
    "\n",
    "print(f\"Fichier log créé avec {50000} entrées\")\n",
    "\n",
    "# TODO: Implémenter le pipeline de traitement des logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Le module itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "# chain - combiner plusieurs itérables\n",
    "liste1 = [1, 2, 3]\n",
    "liste2 = [4, 5, 6]\n",
    "liste3 = [7, 8, 9]\n",
    "combine = list(itertools.chain(liste1, liste2, liste3))\n",
    "print(\"Chaîné :\", combine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# islice - découper un itérateur\n",
    "infini = itertools.count(start=0, step=2)  # 0, 2, 4, 6, ...\n",
    "premiers_10_pairs = list(itertools.islice(infini, 10))\n",
    "print(\"10 premiers nombres pairs :\", premiers_10_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby - grouper les éléments consécutifs\n",
    "donnees = [('A', 1), ('A', 2), ('B', 3), ('B', 4), ('A', 5)]\n",
    "for cle, groupe in itertools.groupby(donnees, key=lambda x: x[0]):\n",
    "    print(f\"Clé : {cle}, Groupe : {list(groupe)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# product - produit cartésien\n",
    "couleurs = ['rouge', 'bleu']\n",
    "tailles = ['S', 'M', 'L']\n",
    "combinaisons = list(itertools.product(couleurs, tailles))\n",
    "print(\"Combinaisons produit :\", combinaisons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.3** : Utilisez `itertools` pour :\n",
    "1. Générer toutes les paires de deux listes sans créer de listes intermédiaires\n",
    "2. Créer des lots de 100 éléments à partir d'un grand itérateur\n",
    "3. Implémenter une fenêtre glissante de taille 3 sur un itérateur\n",
    "4. Trouver les 1000 premiers nombres divisibles par 7 et 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implémenter les exercices itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nettoyage des fichiers de test\n",
    "import os\n",
    "for f in [fichier_test, fichier_log]:\n",
    "    if os.path.exists(f):\n",
    "        os.remove(f)\n",
    "        print(f\"Supprimé {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 4 [★★] - Introduction au Multiprocessing\n",
    "\n",
    "Le Global Interpreter Lock (GIL) de Python empêche l'exécution parallèle réelle des threads. Pour les tâches intensives en CPU, nous utilisons le module `multiprocessing` pour atteindre le parallélisme via des processus séparés."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Comprendre le parallélisme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "# Obtenir le nombre de CPU\n",
    "nb_cpu = mp.cpu_count()\n",
    "print(f\"Nombre de cœurs CPU : {nb_cpu}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Une fonction intensive en CPU\n",
    "def est_premier(n):\n",
    "    \"\"\"Vérifie si n est premier (intensif en CPU pour les grands n)\"\"\"\n",
    "    if n < 2:\n",
    "        return False\n",
    "    if n == 2:\n",
    "        return True\n",
    "    if n % 2 == 0:\n",
    "        return False\n",
    "    for i in range(3, int(n**0.5) + 1, 2):\n",
    "        if n % i == 0:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def compter_premiers_dans_plage(debut, fin):\n",
    "    \"\"\"Compte les nombres premiers dans une plage\"\"\"\n",
    "    return sum(1 for n in range(debut, fin) if est_premier(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Exécution séquentielle\n",
    "temps_debut = time.perf_counter()\n",
    "resultat_sequentiel = compter_premiers_dans_plage(2, 100000)\n",
    "temps_sequentiel = time.perf_counter() - temps_debut\n",
    "\n",
    "print(f\"Séquentiel : Trouvé {resultat_sequentiel} nombres premiers en {temps_sequentiel:.2f} secondes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Utilisation de multiprocessing.Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrapper_verifier_premier(n): \n",
    "    \"\"\"Wrapper qui retourne un tuple (n, est_premier)\"\"\"\n",
    "    return (n, est_premier(n)) \n",
    "\n",
    "# Exécution parallèle avec Pool \n",
    "nombres = list(range(2, 100)) \n",
    "temps_debut = time.perf_counter() \n",
    "with mp.Pool(processes=nb_cpu) as pool: \n",
    "    resultats = pool.map(wrapper_verifier_premier, nombres) \n",
    "\n",
    "resultat_parallele = sum(1 for _, est_p in resultats if est_p) \n",
    "temps_parallele = time.perf_counter() - temps_debut \n",
    "\n",
    "print(f\"Parallèle ({nb_cpu} cœurs) : Trouvé {resultat_parallele} premiers en {temps_parallele:.2f} secondes\") \n",
    "print(f\"Accélération : {temps_sequentiel / temps_parallele:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Comparaison des méthodes Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def carre_lent(x):\n",
    "    \"\"\"Une fonction lente pour la démonstration\"\"\"\n",
    "    time.sleep(0.01)  # Simuler du travail\n",
    "    return x * x\n",
    "\n",
    "nombres = list(range(100))\n",
    "\n",
    "# pool.map - bloque jusqu'à ce que tous les résultats soient prêts, ordonné\n",
    "debut = time.perf_counter()\n",
    "with mp.Pool(4) as pool:\n",
    "    resultats_map = pool.map(carre_lent, nombres)\n",
    "print(f\"pool.map : {time.perf_counter() - debut:.2f}s, 5 premiers : {resultats_map[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pool.imap - retourne un itérateur, ordonné, peut commencer le traitement avant que tout soit fait\n",
    "debut = time.perf_counter()\n",
    "with mp.Pool(4) as pool:\n",
    "    resultats_imap = list(pool.imap(carre_lent, nombres))\n",
    "print(f\"pool.imap : {time.perf_counter() - debut:.2f}s, 5 premiers : {resultats_imap[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pool.imap_unordered - retourne un itérateur, non ordonné (plus rapide pour les charges inégales)\n",
    "debut = time.perf_counter()\n",
    "with mp.Pool(4) as pool:\n",
    "    resultats_non_ordonnes = list(pool.imap_unordered(carre_lent, nombres))\n",
    "print(f\"pool.imap_unordered : {time.perf_counter() - debut:.2f}s\")\n",
    "print(f\"Les résultats ne sont pas ordonnés : {resultats_non_ordonnes[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.1** : Comparez les performances de `pool.map`, `pool.imap` et `pool.imap_unordered` sur une charge de travail où différents éléments prennent des temps différents. Quand chaque méthode est-elle la plus appropriée ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Comparer les méthodes pool avec une charge de travail inégale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Stratégies de découpage (Chunking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def travail_simple(x):\n",
    "    return x * x\n",
    "\n",
    "donnees = list(range(100000))\n",
    "\n",
    "# Tester différentes tailles de chunks\n",
    "tailles_chunk = [1, 10, 100, 1000, 10000]\n",
    "\n",
    "for taille_chunk in tailles_chunk:\n",
    "    debut = time.perf_counter()\n",
    "    with mp.Pool(4) as pool:\n",
    "        resultats = pool.map(travail_simple, donnees, chunksize=taille_chunk)\n",
    "    temps_ecoule = time.perf_counter() - debut\n",
    "    print(f\"Taille chunk {taille_chunk:5d} : {temps_ecoule:.4f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.2** : Expérimentez avec différentes tailles de chunks pour une tâche intensive en CPU. Trouvez la taille de chunk optimale et expliquez pourquoi elle est la plus performante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Trouver la taille de chunk optimale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Application pratique : Traitement de fichiers en parallèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "\n",
    "def telecharger_entite_wikidata(id_entite):\n",
    "    \"\"\"Télécharge une entité Wikidata et retourne ses données\"\"\"\n",
    "    url = f\"https://www.wikidata.org/wiki/Special:EntityData/{id_entite}.json\"\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            return {\"id\": id_entite, \"statut\": \"succes\", \"taille\": len(response.content)}\n",
    "        else:\n",
    "            return {\"id\": id_entite, \"statut\": \"erreur\", \"code\": response.status_code}\n",
    "    except Exception as e:\n",
    "        return {\"id\": id_entite, \"statut\": \"erreur\", \"message\": str(e)}\n",
    "\n",
    "# Télécharger des entités en parallèle\n",
    "entites = [f\"Q{i}\" for i in range(1, 21)]  # Q1 à Q20\n",
    "\n",
    "print(\"Téléchargement des entités Wikidata...\")\n",
    "debut = time.perf_counter()\n",
    "with mp.Pool(4) as pool:\n",
    "    resultats = pool.map(telecharger_entite_wikidata, entites)\n",
    "temps_ecoule = time.perf_counter() - debut\n",
    "\n",
    "print(f\"\\nTéléchargé {len(resultats)} entités en {temps_ecoule:.2f}s\")\n",
    "for r in resultats[:5]:\n",
    "    print(f\"  {r['id']}: {r['statut']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.3** : Écrivez un programme qui :\n",
    "1. Télécharge 50 pages Wikipedia en parallèle\n",
    "2. Compte le nombre de liens sur chaque page\n",
    "3. Retourne la page avec le plus de liens\n",
    "\n",
    "Implémentez avec une gestion d'erreurs appropriée et une limitation de débit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implémenter le web scraping parallèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.4** : Créez un pipeline de traitement d'images parallèle qui :\n",
    "1. Lit des images depuis un répertoire\n",
    "2. Redimensionne chaque image en 256x256\n",
    "3. Convertit en niveaux de gris\n",
    "4. Sauvegarde les images traitées\n",
    "\n",
    "Comparez les temps d'exécution séquentielle vs parallèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implémenter le traitement d'images parallèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 5 [★★] - Communication Inter-processus : Queues et Pipes\n",
    "\n",
    "Quand les processus ont besoin de partager des données, nous utilisons des mécanismes de communication inter-processus (IPC) comme les Queues et les Pipes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. multiprocessing.Queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Queue\n",
    "import time\n",
    "\n",
    "def producteur(queue, n_elements):\n",
    "    \"\"\"Produit des éléments et les met dans la queue\"\"\"\n",
    "    for i in range(n_elements):\n",
    "        element = f\"element_{i}\"\n",
    "        queue.put(element)\n",
    "        print(f\"Produit : {element}\")\n",
    "        time.sleep(0.1)\n",
    "    queue.put(None)  # Sentinelle pour signaler la fin\n",
    "\n",
    "def consommateur(queue):\n",
    "    \"\"\"Consomme les éléments de la queue\"\"\"\n",
    "    while True:\n",
    "        element = queue.get()\n",
    "        if element is None:\n",
    "            break\n",
    "        print(f\"Consommé : {element}\")\n",
    "\n",
    "# Note: Ce pattern fonctionne mieux en tant que script, pas dans Jupyter\n",
    "# Dans Jupyter, nous simulerons avec des threads pour la démonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Démonstration simplifiée de Queue avec des threads (fonctionne dans Jupyter)\n",
    "from queue import Queue\n",
    "from threading import Thread\n",
    "\n",
    "def producteur_thread(queue, n_elements):\n",
    "    for i in range(n_elements):\n",
    "        element = f\"element_{i}\"\n",
    "        queue.put(element)\n",
    "    queue.put(None)\n",
    "\n",
    "def consommateur_thread(queue, resultats):\n",
    "    while True:\n",
    "        element = queue.get()\n",
    "        if element is None:\n",
    "            break\n",
    "        resultats.append(f\"traite_{element}\")\n",
    "\n",
    "q = Queue()\n",
    "resultats = []\n",
    "\n",
    "prod = Thread(target=producteur_thread, args=(q, 10))\n",
    "cons = Thread(target=consommateur_thread, args=(q, resultats))\n",
    "\n",
    "prod.start()\n",
    "cons.start()\n",
    "prod.join()\n",
    "cons.join()\n",
    "\n",
    "print(\"Résultats :\", resultats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Pattern Producteur-Consommateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import Queue\n",
    "from threading import Thread\n",
    "import time\n",
    "\n",
    "def producteur_donnees(queue, source_donnees, n_workers):\n",
    "    \"\"\"Produit des éléments de données depuis une source\"\"\"\n",
    "    for element in source_donnees:\n",
    "        queue.put(element)\n",
    "    # Envoyer le signal de terminaison pour chaque worker\n",
    "    for _ in range(n_workers):\n",
    "        queue.put(None)\n",
    "\n",
    "def processeur_donnees(queue, resultats, id_worker):\n",
    "    \"\"\"Traite les éléments de données de la queue\"\"\"\n",
    "    resultats_locaux = []\n",
    "    while True:\n",
    "        element = queue.get()\n",
    "        if element is None:\n",
    "            break\n",
    "        # Simuler le traitement\n",
    "        traite = element ** 2\n",
    "        resultats_locaux.append(traite)\n",
    "    resultats[id_worker] = resultats_locaux\n",
    "\n",
    "# Créer la queue de travail et le stockage des résultats\n",
    "queue_travail = Queue()\n",
    "n_workers = 4\n",
    "resultats = {}\n",
    "donnees = list(range(100))\n",
    "\n",
    "# Démarrer les workers\n",
    "workers = []\n",
    "for i in range(n_workers):\n",
    "    w = Thread(target=processeur_donnees, args=(queue_travail, resultats, i))\n",
    "    w.start()\n",
    "    workers.append(w)\n",
    "\n",
    "# Démarrer le producteur\n",
    "thread_producteur = Thread(target=producteur_donnees, args=(queue_travail, donnees, n_workers))\n",
    "thread_producteur.start()\n",
    "\n",
    "# Attendre la fin\n",
    "thread_producteur.join()\n",
    "for w in workers:\n",
    "    w.join()\n",
    "\n",
    "# Combiner les résultats\n",
    "tous_resultats = []\n",
    "for resultats_worker in resultats.values():\n",
    "    tous_resultats.extend(resultats_worker)\n",
    "\n",
    "print(f\"Traité {len(tous_resultats)} éléments\")\n",
    "print(f\"Résultats exemples : {sorted(tous_resultats)[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5.1** : Implémentez un système producteur-consommateur qui :\n",
    "1. A un producteur générant des nombres aléatoires\n",
    "2. A 4 workers traitant les nombres (vérifier si premier)\n",
    "3. A un agrégateur collectant et résumant les résultats\n",
    "4. Utilise des queues bornées pour éviter les problèmes de mémoire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implémenter producteur-consommateur avec agrégateur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Mémoire partagée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Value, Array, Lock\n",
    "\n",
    "# Valeur partagée (valeur unique)\n",
    "compteur_partage = Value('i', 0)  # 'i' = entier\n",
    "\n",
    "# Tableau partagé\n",
    "tableau_partage = Array('d', [0.0] * 10)  # 'd' = double\n",
    "\n",
    "print(f\"Compteur initial : {compteur_partage.value}\")\n",
    "print(f\"Tableau initial : {list(tableau_partage)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Démonstration de condition de course (conceptuel - mieux visible avec multiprocessing)\n",
    "from threading import Thread, Lock\n",
    "\n",
    "compteur = 0\n",
    "verrou = Lock()\n",
    "\n",
    "def incrementer_non_securise():\n",
    "    global compteur\n",
    "    for _ in range(100000):\n",
    "        compteur += 1\n",
    "\n",
    "def incrementer_securise():\n",
    "    global compteur\n",
    "    for _ in range(100000):\n",
    "        with verrou:\n",
    "            compteur += 1\n",
    "\n",
    "# Version non sécurisée - peut donner un mauvais résultat\n",
    "compteur = 0\n",
    "threads = [Thread(target=incrementer_non_securise) for _ in range(4)]\n",
    "for t in threads:\n",
    "    t.start()\n",
    "for t in threads:\n",
    "    t.join()\n",
    "print(f\"Compteur non sécurisé (attendu 400000) : {compteur}\")\n",
    "\n",
    "# Version sécurisée - toujours correcte\n",
    "compteur = 0\n",
    "threads = [Thread(target=incrementer_securise) for _ in range(4)]\n",
    "for t in threads:\n",
    "    t.start()\n",
    "for t in threads:\n",
    "    t.join()\n",
    "print(f\"Compteur sécurisé (attendu 400000) : {compteur}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5.2** : Implémentez un compteur de mots parallèle utilisant la mémoire partagée :\n",
    "1. Plusieurs workers lisent différentes parties d'un fichier texte\n",
    "2. Chaque worker met à jour un dictionnaire partagé de comptages de mots\n",
    "3. Utilisez un verrouillage approprié pour éviter les conditions de course\n",
    "4. Comparez les performances avec et sans verrouillage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implémenter le compteur de mots parallèle avec mémoire partagée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 6 [★★★] - concurrent.futures et Patterns Asynchrones\n",
    "\n",
    "Le module `concurrent.futures` fournit une interface de haut niveau pour exécuter des callables de manière asynchrone en utilisant des threads ou des processus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. ThreadPoolExecutor vs ProcessPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed\n",
    "import time\n",
    "\n",
    "def tache_intensive_cpu(n):\n",
    "    \"\"\"Tâche intensive en CPU\"\"\"\n",
    "    total = 0\n",
    "    for i in range(n):\n",
    "        total += i ** 2\n",
    "    return total\n",
    "\n",
    "def tache_intensive_io(url):\n",
    "    \"\"\"Tâche intensive en I/O\"\"\"\n",
    "    time.sleep(0.1)  # Simuler le délai réseau\n",
    "    return f\"Récupéré {url}\"\n",
    "\n",
    "# CPU-bound : ProcessPoolExecutor est plus rapide\n",
    "donnees = [1000000] * 8\n",
    "\n",
    "debut = time.perf_counter()\n",
    "with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "    resultats = list(executor.map(tache_intensive_cpu, donnees))\n",
    "print(f\"ThreadPool (tâche CPU) : {time.perf_counter() - debut:.2f}s\")\n",
    "\n",
    "debut = time.perf_counter()\n",
    "with ProcessPoolExecutor(max_workers=4) as executor:\n",
    "    resultats = list(executor.map(tache_intensive_cpu, donnees))\n",
    "print(f\"ProcessPool (tâche CPU) : {time.perf_counter() - debut:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I/O-bound : ThreadPoolExecutor est suffisant et a moins d'overhead\n",
    "urls = [f\"http://exemple.com/page{i}\" for i in range(20)]\n",
    "\n",
    "debut = time.perf_counter()\n",
    "with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "    resultats = list(executor.map(tache_intensive_io, urls))\n",
    "print(f\"ThreadPool (tâche I/O) : {time.perf_counter() - debut:.2f}s\")\n",
    "\n",
    "debut = time.perf_counter()\n",
    "with ProcessPoolExecutor(max_workers=4) as executor:\n",
    "    resultats = list(executor.map(tache_intensive_io, urls))\n",
    "print(f\"ProcessPool (tâche I/O) : {time.perf_counter() - debut:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Travailler avec les Futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import random\n",
    "\n",
    "def tache_temps_variable(id_tache):\n",
    "    \"\"\"Tâche avec temps d'exécution variable\"\"\"\n",
    "    temps_sommeil = random.uniform(0.1, 1.0)\n",
    "    time.sleep(temps_sommeil)\n",
    "    return {\"id_tache\": id_tache, \"duree\": temps_sommeil}\n",
    "\n",
    "# Traiter les résultats dès qu'ils sont prêts\n",
    "with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "    # Soumettre toutes les tâches\n",
    "    futures = {executor.submit(tache_temps_variable, i): i for i in range(10)}\n",
    "    \n",
    "    # Traiter les résultats dès qu'ils sont prêts\n",
    "    for future in as_completed(futures):\n",
    "        id_tache = futures[future]\n",
    "        resultat = future.result()\n",
    "        print(f\"Tâche {id_tache} terminée en {resultat['duree']:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gestion des exceptions\n",
    "def peut_echouer(id_tache):\n",
    "    if random.random() < 0.3:  # 30% de chance d'échec\n",
    "        raise ValueError(f\"Tâche {id_tache} a échoué !\")\n",
    "    return f\"Tâche {id_tache} réussie\"\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "    futures = [executor.submit(peut_echouer, i) for i in range(10)]\n",
    "    \n",
    "    for future in as_completed(futures):\n",
    "        try:\n",
    "            resultat = future.result()\n",
    "            print(resultat)\n",
    "        except ValueError as e:\n",
    "            print(f\"Erreur : {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 6.1** : Implémentez un planificateur de tâches qui :\n",
    "1. Accepte des tâches avec différentes priorités\n",
    "2. Traite les tâches de priorité supérieure en premier\n",
    "3. Implémente la gestion des timeouts pour les tâches lentes\n",
    "4. Fournit un rapport de progression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implémenter le planificateur de tâches avec priorité"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Introduction à asyncio (Sujet avancé optionnel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "async def tache_async(id_tache, delai):\n",
    "    \"\"\"Une tâche async qui simule des I/O\"\"\"\n",
    "    print(f\"Tâche {id_tache} démarrée\")\n",
    "    await asyncio.sleep(delai)\n",
    "    print(f\"Tâche {id_tache} terminée\")\n",
    "    return f\"Résultat de la tâche {id_tache}\"\n",
    "\n",
    "async def main():\n",
    "    # Exécuter plusieurs tâches en concurrence\n",
    "    taches = [\n",
    "        tache_async(1, 1),\n",
    "        tache_async(2, 2),\n",
    "        tache_async(3, 1),\n",
    "    ]\n",
    "    resultats = await asyncio.gather(*taches)\n",
    "    return resultats\n",
    "\n",
    "# Dans Jupyter, utiliser await directement\n",
    "resultats = await main()\n",
    "print(\"Résultats :\", resultats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 6.2** : Comparez les performances de :\n",
    "1. Opérations I/O séquentielles\n",
    "2. ThreadPoolExecutor\n",
    "3. asyncio\n",
    "\n",
    "Pour télécharger plusieurs pages web. Quelle approche est la meilleure pour les tâches I/O-bound ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Comparer les approches I/O"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 7 [★★★] - Benchmarking et Optimisation des Performances\n",
    "\n",
    "Comprendre comment mesurer et optimiser le code parallèle est essentiel pour utiliser efficacement ces techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Mesurer le temps d'exécution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from functools import wraps\n",
    "\n",
    "def decorateur_timing(func):\n",
    "    \"\"\"Décorateur pour mesurer le temps d'exécution d'une fonction\"\"\"\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        debut = time.perf_counter()\n",
    "        resultat = func(*args, **kwargs)\n",
    "        temps_ecoule = time.perf_counter() - debut\n",
    "        print(f\"{func.__name__} a pris {temps_ecoule:.4f}s\")\n",
    "        return resultat\n",
    "    return wrapper\n",
    "\n",
    "@decorateur_timing\n",
    "def fonction_lente():\n",
    "    time.sleep(0.5)\n",
    "    return \"Terminé\"\n",
    "\n",
    "fonction_lente()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utiliser timeit pour des mesures plus précises\n",
    "import timeit\n",
    "\n",
    "def fonction_test():\n",
    "    return sum(i**2 for i in range(1000))\n",
    "\n",
    "# Timer 1000 exécutions\n",
    "temps_execution = timeit.timeit(fonction_test, number=1000)\n",
    "print(f\"Temps moyen par appel : {temps_execution/1000*1000:.4f}ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Loi d'Amdahl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def loi_amdahl(p, n):\n",
    "    \"\"\"\n",
    "    Calcule l'accélération théorique en utilisant la loi d'Amdahl.\n",
    "    p: fraction du programme qui peut être parallélisée (0 à 1)\n",
    "    n: nombre de processeurs\n",
    "    \"\"\"\n",
    "    return 1 / ((1 - p) + p / n)\n",
    "\n",
    "# Visualiser la loi d'Amdahl\n",
    "processeurs = np.arange(1, 65)\n",
    "fractions_paralleles = [0.5, 0.75, 0.9, 0.95, 0.99]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "for p in fractions_paralleles:\n",
    "    accelerations = [loi_amdahl(p, n) for n in processeurs]\n",
    "    plt.plot(processeurs, accelerations, label=f'{p*100:.0f}% parallélisable')\n",
    "\n",
    "plt.xlabel('Nombre de processeurs')\n",
    "plt.ylabel('Accélération')\n",
    "plt.title(\"Loi d'Amdahl : Limites théoriques d'accélération\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Benchmarking du code parallèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "import time\n",
    "\n",
    "def intensif_cpu(n):\n",
    "    \"\"\"Calcul intensif en CPU\"\"\"\n",
    "    total = 0\n",
    "    for i in range(n):\n",
    "        total += i ** 0.5\n",
    "    return total\n",
    "\n",
    "def benchmark_parallele(func, donnees, max_workers=None):\n",
    "    \"\"\"Benchmark une fonction avec différents nombres de workers\"\"\"\n",
    "    if max_workers is None:\n",
    "        max_workers = mp.cpu_count()\n",
    "    \n",
    "    resultats = []\n",
    "    \n",
    "    # Ligne de base séquentielle\n",
    "    debut = time.perf_counter()\n",
    "    resultats_sequentiels = [func(d) for d in donnees]\n",
    "    temps_sequentiel = time.perf_counter() - debut\n",
    "    resultats.append((1, temps_sequentiel, 1.0))\n",
    "    print(f\"Séquentiel : {temps_sequentiel:.4f}s\")\n",
    "    \n",
    "    # Parallèle avec différents nombres de workers\n",
    "    for n_workers in range(2, max_workers + 1):\n",
    "        debut = time.perf_counter()\n",
    "        with mp.Pool(n_workers) as pool:\n",
    "            resultats_paralleles = pool.map(func, donnees)\n",
    "        temps_parallele = time.perf_counter() - debut\n",
    "        acceleration = temps_sequentiel / temps_parallele\n",
    "        efficacite = acceleration / n_workers\n",
    "        resultats.append((n_workers, temps_parallele, acceleration))\n",
    "        print(f\"Workers={n_workers}: {temps_parallele:.4f}s, Accélération={acceleration:.2f}x, Efficacité={efficacite:.1%}\")\n",
    "    \n",
    "    return resultats\n",
    "\n",
    "# Exécuter le benchmark\n",
    "donnees = [1000000] * 16\n",
    "resultats_benchmark = benchmark_parallele(intensif_cpu, donnees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 7.1** : Créez une suite de benchmarks complète qui :\n",
    "1. Teste différentes tailles de chunks\n",
    "2. Teste différentes tailles de données\n",
    "3. Génère des visualisations comparant les performances\n",
    "4. Identifie la configuration optimale pour votre charge de travail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Créer une suite de benchmarks complète"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Profilage et optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\n",
    "import pstats\n",
    "from io import StringIO\n",
    "\n",
    "def profiler_fonction(func, *args, **kwargs):\n",
    "    \"\"\"Profile une fonction et affiche les résultats\"\"\"\n",
    "    profiler = cProfile.Profile()\n",
    "    profiler.enable()\n",
    "    resultat = func(*args, **kwargs)\n",
    "    profiler.disable()\n",
    "    \n",
    "    stream = StringIO()\n",
    "    stats = pstats.Stats(profiler, stream=stream)\n",
    "    stats.sort_stats('cumulative')\n",
    "    stats.print_stats(10)\n",
    "    print(stream.getvalue())\n",
    "    \n",
    "    return resultat\n",
    "\n",
    "def fonction_a_profiler():\n",
    "    \"\"\"Exemple de fonction à profiler\"\"\"\n",
    "    donnees = [i**2 for i in range(100000)]\n",
    "    filtre = list(filter(lambda x: x % 2 == 0, donnees))\n",
    "    total = sum(filtre)\n",
    "    return total\n",
    "\n",
    "profiler_fonction(fonction_a_profiler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 7.2** : Profilez et optimisez le pipeline de traitement d'images de l'Exercice 4 :\n",
    "1. Identifiez les trois plus grands goulots d'étranglement\n",
    "2. Appliquez des optimisations à chacun\n",
    "3. Mesurez l'amélioration\n",
    "4. Documentez votre processus d'optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Profiler et optimiser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Étude de cas réel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 7.3** : Construisez un système complet de traitement de données qui :\n",
    "1. Lit des données depuis plusieurs fichiers CSV (100+ fichiers)\n",
    "2. Nettoie et transforme chaque fichier\n",
    "3. Agrège les résultats de tous les fichiers\n",
    "4. Écrit la sortie finale\n",
    "\n",
    "Implémentez les versions séquentielle et parallèle, benchmarkez-les, et documentez l'accélération obtenue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implémenter l'étude de cas réel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Résumé\n",
    "\n",
    "Dans ce TP, vous avez appris :\n",
    "\n",
    "1. **Programmation fonctionnelle** : Utilisation de `filter()`, `map()`, `reduce()` pour les transformations de données\n",
    "2. **Expressions lambda** : Création de fonctions concises en ligne\n",
    "3. **Générateurs** : Traitement efficace en mémoire des grands ensembles de données\n",
    "4. **Multiprocessing** : Exécution parallèle avec `Pool` et parallélisme basé sur les processus\n",
    "5. **Communication inter-processus** : Utilisation des Queues et de la mémoire partagée\n",
    "6. **concurrent.futures** : Interface de haut niveau pour l'exécution parallèle\n",
    "7. **Optimisation des performances** : Benchmarking, profilage et optimisation du code parallèle\n",
    "\n",
    "Ces concepts forment la base des frameworks de calcul distribué comme Apache Spark, que vous explorerez dans le TP 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prochaines étapes\n",
    "\n",
    "Continuez vers le **TP 5 : Apache Spark pour le traitement de données massives** pour apprendre comment ces concepts de traitement parallèle s'étendent au calcul distribué sur des clusters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

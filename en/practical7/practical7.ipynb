{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical 7: Kubernetes for Scalable Data Pipelines\n",
    "\n",
    "## Goals\n",
    "\n",
    "This practical session introduces Kubernetes (K8s), the industry-standard container orchestration platform. You will learn how to deploy, scale, and manage containerized data processing applications in a production-like environment.\n",
    "\n",
    "### Learning Objectives\n",
    "* Understand Kubernetes architecture and core concepts\n",
    "* Deploy applications using Pods, Deployments, and Services\n",
    "* Manage configuration with ConfigMaps and Secrets\n",
    "* Implement persistent storage with PersistentVolumes\n",
    "* Run batch and scheduled jobs with Jobs and CronJobs\n",
    "* Scale applications automatically with Horizontal Pod Autoscaler\n",
    "* Deploy Spark applications on Kubernetes\n",
    "* Monitor and troubleshoot Kubernetes workloads\n",
    "\n",
    "### Prerequisites\n",
    "* Completion of Practical 6 (Docker)\n",
    "* Docker Desktop with Kubernetes enabled, OR\n",
    "* Minikube installed ([Installation Guide](https://minikube.sigs.k8s.io/docs/start/))\n",
    "* kubectl CLI installed ([Installation Guide](https://kubernetes.io/docs/tasks/tools/))\n",
    "\n",
    "### Installation Verification\n",
    "\n",
    "```bash\n",
    "# Check kubectl version\n",
    "kubectl version --client\n",
    "\n",
    "# Check cluster status\n",
    "kubectl cluster-info\n",
    "\n",
    "# List nodes\n",
    "kubectl get nodes\n",
    "```\n",
    "\n",
    "### Exercises Overview\n",
    "\n",
    "| Exercise | Topic | Difficulty |\n",
    "|----------|-------|------------|\n",
    "| 1 | Kubernetes Architecture and kubectl Basics | ★ |\n",
    "| 2 | Pods and Deployments | ★ |\n",
    "| 3 | Services and Networking | ★★ |\n",
    "| 4 | ConfigMaps and Secrets | ★★ |\n",
    "| 5 | Persistent Storage | ★★ |\n",
    "| 6 | Jobs and CronJobs for Batch Processing | ★★ |\n",
    "| 7 | Horizontal Pod Autoscaling | ★★★ |\n",
    "| 8 | Deploying Data Processing Pipelines | ★★★ |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 1: Kubernetes Architecture and kubectl Basics [★]\n",
    "\n",
    "### Kubernetes Architecture\n",
    "\n",
    "```\n",
    "┌────────────────────────────────────────────────────────────────────┐\n",
    "│                        Control Plane                               │\n",
    "│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐             │\n",
    "│  │  API Server  │  │  Scheduler   │  │  Controller  │             │\n",
    "│  │              │  │              │  │   Manager    │             │\n",
    "│  └──────────────┘  └──────────────┘  └──────────────┘             │\n",
    "│                           │                                        │\n",
    "│                    ┌──────┴──────┐                                │\n",
    "│                    │    etcd     │                                │\n",
    "│                    │  (Storage)  │                                │\n",
    "│                    └─────────────┘                                │\n",
    "└────────────────────────────────────────────────────────────────────┘\n",
    "                              │\n",
    "         ┌────────────────────┼────────────────────┐\n",
    "         │                    │                    │\n",
    "         ▼                    ▼                    ▼\n",
    "┌─────────────────┐  ┌─────────────────┐  ┌─────────────────┐\n",
    "│   Worker Node   │  │   Worker Node   │  │   Worker Node   │\n",
    "│  ┌───────────┐  │  │  ┌───────────┐  │  │  ┌───────────┐  │\n",
    "│  │  kubelet  │  │  │  │  kubelet  │  │  │  │  kubelet  │  │\n",
    "│  └───────────┘  │  │  └───────────┘  │  │  └───────────┘  │\n",
    "│  ┌───────────┐  │  │  ┌───────────┐  │  │  ┌───────────┐  │\n",
    "│  │kube-proxy │  │  │  │kube-proxy │  │  │  │kube-proxy │  │\n",
    "│  └───────────┘  │  │  └───────────┘  │  │  └───────────┘  │\n",
    "│  ┌───┐ ┌───┐    │  │  ┌───┐ ┌───┐    │  │  ┌───┐ ┌───┐    │\n",
    "│  │Pod│ │Pod│    │  │  │Pod│ │Pod│    │  │  │Pod│ │Pod│    │\n",
    "│  └───┘ └───┘    │  │  └───┘ └───┘    │  │  └───┘ └───┘    │\n",
    "└─────────────────┘  └─────────────────┘  └─────────────────┘\n",
    "```\n",
    "\n",
    "### Key Components\n",
    "\n",
    "**Control Plane:**\n",
    "- **API Server**: Entry point for all REST commands\n",
    "- **etcd**: Distributed key-value store for cluster state\n",
    "- **Scheduler**: Assigns pods to nodes\n",
    "- **Controller Manager**: Runs control loops (ReplicaSet, Deployment, etc.)\n",
    "\n",
    "**Worker Nodes:**\n",
    "- **kubelet**: Agent that runs on each node\n",
    "- **kube-proxy**: Network proxy for service networking\n",
    "- **Container Runtime**: Docker, containerd, or CRI-O"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kubectl Basic Commands\n",
    "\n",
    "```bash\n",
    "# Get cluster information\n",
    "kubectl cluster-info\n",
    "\n",
    "# List all nodes\n",
    "kubectl get nodes\n",
    "\n",
    "# List all namespaces\n",
    "kubectl get namespaces\n",
    "\n",
    "# List all resources in current namespace\n",
    "kubectl get all\n",
    "\n",
    "# List pods with more details\n",
    "kubectl get pods -o wide\n",
    "\n",
    "# Describe a resource\n",
    "kubectl describe pod <pod-name>\n",
    "\n",
    "# View logs\n",
    "kubectl logs <pod-name>\n",
    "\n",
    "# Execute command in a pod\n",
    "kubectl exec -it <pod-name> -- /bin/bash\n",
    "\n",
    "# Apply a configuration\n",
    "kubectl apply -f <file.yaml>\n",
    "\n",
    "# Delete a resource\n",
    "kubectl delete -f <file.yaml>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with Namespaces\n",
    "\n",
    "Namespaces provide isolation and organization for resources.\n",
    "\n",
    "```bash\n",
    "# Create a namespace\n",
    "kubectl create namespace data-processing\n",
    "\n",
    "# List pods in a specific namespace\n",
    "kubectl get pods -n data-processing\n",
    "\n",
    "# Set default namespace for current context\n",
    "kubectl config set-context --current --namespace=data-processing\n",
    "\n",
    "# List all resources across all namespaces\n",
    "kubectl get pods --all-namespaces\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YAML Manifests\n",
    "\n",
    "Kubernetes uses YAML files to define resources. Basic structure:\n",
    "\n",
    "```yaml\n",
    "apiVersion: v1              # API version\n",
    "kind: Pod                   # Resource type\n",
    "metadata:\n",
    "  name: my-pod              # Resource name\n",
    "  namespace: default        # Namespace\n",
    "  labels:                   # Key-value labels\n",
    "    app: myapp\n",
    "spec:                       # Resource specification\n",
    "  # ... resource-specific fields\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions - Exercise 1\n",
    "\n",
    "**Q1.1** Explore your Kubernetes cluster:\n",
    "- List all nodes and their status\n",
    "- Describe one node to see its capacity and allocatable resources\n",
    "- List all namespaces and pods across the cluster\n",
    "\n",
    "**Q1.2** Create a namespace called `tdm-practicals` and set it as your default namespace.\n",
    "\n",
    "**Q1.3** Use `kubectl explain` to explore the Pod resource:\n",
    "- What fields are available in `spec.containers`?\n",
    "- What is the difference between `resources.limits` and `resources.requests`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 2: Pods and Deployments [★]\n",
    "\n",
    "### Pods\n",
    "\n",
    "A Pod is the smallest deployable unit in Kubernetes. It can contain one or more containers that share storage and network.\n",
    "\n",
    "**Simple Pod (pod.yaml):**\n",
    "\n",
    "```yaml\n",
    "apiVersion: v1\n",
    "kind: Pod\n",
    "metadata:\n",
    "  name: python-pod\n",
    "  labels:\n",
    "    app: python-demo\n",
    "spec:\n",
    "  containers:\n",
    "  - name: python\n",
    "    image: python:3.10-slim\n",
    "    command: [\"python\", \"-c\"]\n",
    "    args:\n",
    "    - |\n",
    "      import time\n",
    "      while True:\n",
    "          print(f\"Hello from Kubernetes at {time.ctime()}\")\n",
    "          time.sleep(5)\n",
    "    resources:\n",
    "      requests:\n",
    "        memory: \"64Mi\"\n",
    "        cpu: \"100m\"\n",
    "      limits:\n",
    "        memory: \"128Mi\"\n",
    "        cpu: \"200m\"\n",
    "```\n",
    "\n",
    "```bash\n",
    "# Create the pod\n",
    "kubectl apply -f pod.yaml\n",
    "\n",
    "# View logs\n",
    "kubectl logs python-pod -f\n",
    "\n",
    "# Delete the pod\n",
    "kubectl delete pod python-pod\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deployments\n",
    "\n",
    "Deployments manage ReplicaSets and provide declarative updates for Pods.\n",
    "\n",
    "**Deployment (deployment.yaml):**\n",
    "\n",
    "```yaml\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: data-processor\n",
    "  labels:\n",
    "    app: data-processor\n",
    "spec:\n",
    "  replicas: 3\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: data-processor\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: data-processor\n",
    "    spec:\n",
    "      containers:\n",
    "      - name: processor\n",
    "        image: python:3.10-slim\n",
    "        command: [\"python\", \"-c\"]\n",
    "        args:\n",
    "        - |\n",
    "          import socket\n",
    "          import time\n",
    "          hostname = socket.gethostname()\n",
    "          while True:\n",
    "              print(f\"Processing on {hostname}\")\n",
    "              time.sleep(10)\n",
    "        resources:\n",
    "          requests:\n",
    "            memory: \"64Mi\"\n",
    "            cpu: \"100m\"\n",
    "          limits:\n",
    "            memory: \"128Mi\"\n",
    "            cpu: \"200m\"\n",
    "```\n",
    "\n",
    "```bash\n",
    "# Create deployment\n",
    "kubectl apply -f deployment.yaml\n",
    "\n",
    "# View deployment status\n",
    "kubectl get deployments\n",
    "kubectl get pods\n",
    "\n",
    "# Scale deployment\n",
    "kubectl scale deployment data-processor --replicas=5\n",
    "\n",
    "# View deployment history\n",
    "kubectl rollout history deployment/data-processor\n",
    "\n",
    "# Update deployment (change image, etc.)\n",
    "kubectl set image deployment/data-processor processor=python:3.11-slim\n",
    "\n",
    "# Rollback to previous version\n",
    "kubectl rollout undo deployment/data-processor\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pod Lifecycle and Health Checks\n",
    "\n",
    "```yaml\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: web-app\n",
    "spec:\n",
    "  replicas: 2\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: web-app\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: web-app\n",
    "    spec:\n",
    "      containers:\n",
    "      - name: web\n",
    "        image: python:3.10-slim\n",
    "        command: [\"python\", \"-c\"]\n",
    "        args:\n",
    "        - |\n",
    "          from http.server import HTTPServer, SimpleHTTPRequestHandler\n",
    "          print('Starting server on port 8080')\n",
    "          HTTPServer(('0.0.0.0', 8080), SimpleHTTPRequestHandler).serve_forever()\n",
    "        ports:\n",
    "        - containerPort: 8080\n",
    "        livenessProbe:\n",
    "          httpGet:\n",
    "            path: /\n",
    "            port: 8080\n",
    "          initialDelaySeconds: 10\n",
    "          periodSeconds: 5\n",
    "        readinessProbe:\n",
    "          httpGet:\n",
    "            path: /\n",
    "            port: 8080\n",
    "          initialDelaySeconds: 5\n",
    "          periodSeconds: 3\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions - Exercise 2\n",
    "\n",
    "**Q2.1** Create a Deployment for a data processing application that:\n",
    "- Runs 3 replicas\n",
    "- Uses the Python image\n",
    "- Processes data in a loop\n",
    "- Has proper resource limits\n",
    "- Includes liveness and readiness probes\n",
    "\n",
    "**Q2.2** Experiment with scaling:\n",
    "- Scale the deployment to 5 replicas\n",
    "- Observe how Kubernetes distributes pods across nodes\n",
    "- Scale down to 2 replicas and observe pod termination\n",
    "\n",
    "**Q2.3** Perform a rolling update:\n",
    "- Update the image version\n",
    "- Watch the rollout progress\n",
    "- Simulate a failed deployment and rollback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 3: Services and Networking [★★]\n",
    "\n",
    "### Service Types\n",
    "\n",
    "Services expose pods and provide stable networking.\n",
    "\n",
    "```\n",
    "┌────────────────────────────────────────────────────────────┐\n",
    "│                        Service Types                       │\n",
    "├────────────────┬───────────────────────────────────────────┤\n",
    "│ ClusterIP      │ Internal cluster IP (default)             │\n",
    "│ NodePort       │ Exposes on each node's IP at static port  │\n",
    "│ LoadBalancer   │ External load balancer (cloud provider)   │\n",
    "│ ExternalName   │ Maps to external DNS name                 │\n",
    "└────────────────┴───────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ClusterIP Service\n",
    "\n",
    "**service-clusterip.yaml:**\n",
    "\n",
    "```yaml\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  name: data-processor-service\n",
    "spec:\n",
    "  type: ClusterIP\n",
    "  selector:\n",
    "    app: data-processor\n",
    "  ports:\n",
    "  - port: 80          # Service port\n",
    "    targetPort: 8080  # Container port\n",
    "    protocol: TCP\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NodePort Service\n",
    "\n",
    "**service-nodeport.yaml:**\n",
    "\n",
    "```yaml\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  name: web-app-nodeport\n",
    "spec:\n",
    "  type: NodePort\n",
    "  selector:\n",
    "    app: web-app\n",
    "  ports:\n",
    "  - port: 80\n",
    "    targetPort: 8080\n",
    "    nodePort: 30080   # Optional: 30000-32767\n",
    "```\n",
    "\n",
    "```bash\n",
    "# Access the service\n",
    "# http://<node-ip>:30080\n",
    "\n",
    "# With minikube\n",
    "minikube service web-app-nodeport --url\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete Web Application Example\n",
    "\n",
    "**webapp.yaml:**\n",
    "\n",
    "```yaml\n",
    "---\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: flask-app\n",
    "spec:\n",
    "  replicas: 3\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: flask-app\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: flask-app\n",
    "    spec:\n",
    "      containers:\n",
    "      - name: flask\n",
    "        image: python:3.10-slim\n",
    "        command: [\"/bin/bash\", \"-c\"]\n",
    "        args:\n",
    "        - |\n",
    "          pip install flask && python -c \"\n",
    "          from flask import Flask\n",
    "          import socket\n",
    "          app = Flask(__name__)\n",
    "          @app.route('/')\n",
    "          def hello():\n",
    "              return f'Hello from {socket.gethostname()}'\n",
    "          app.run(host='0.0.0.0', port=5000)\n",
    "          \"\n",
    "        ports:\n",
    "        - containerPort: 5000\n",
    "        resources:\n",
    "          requests:\n",
    "            memory: \"128Mi\"\n",
    "            cpu: \"100m\"\n",
    "          limits:\n",
    "            memory: \"256Mi\"\n",
    "            cpu: \"200m\"\n",
    "---\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  name: flask-app-service\n",
    "spec:\n",
    "  type: NodePort\n",
    "  selector:\n",
    "    app: flask-app\n",
    "  ports:\n",
    "  - port: 80\n",
    "    targetPort: 5000\n",
    "    nodePort: 30500\n",
    "```\n",
    "\n",
    "```bash\n",
    "# Apply both resources\n",
    "kubectl apply -f webapp.yaml\n",
    "\n",
    "# Test load balancing (multiple requests show different hostnames)\n",
    "for i in {1..10}; do curl http://localhost:30500; done\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DNS and Service Discovery\n",
    "\n",
    "Kubernetes provides DNS-based service discovery. Services can be accessed by:\n",
    "- `<service-name>` (same namespace)\n",
    "- `<service-name>.<namespace>` (cross-namespace)\n",
    "- `<service-name>.<namespace>.svc.cluster.local` (FQDN)\n",
    "\n",
    "```bash\n",
    "# Test DNS from within a pod\n",
    "kubectl run -it --rm debug --image=busybox -- nslookup flask-app-service\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions - Exercise 3\n",
    "\n",
    "**Q3.1** Create a multi-tier application:\n",
    "- Frontend Deployment and Service (NodePort)\n",
    "- Backend Deployment and Service (ClusterIP)\n",
    "- Frontend communicates with backend via service name\n",
    "\n",
    "**Q3.2** Test service discovery:\n",
    "- Create a debug pod\n",
    "- Use `nslookup` and `curl` to verify service connectivity\n",
    "- Document the DNS resolution process\n",
    "\n",
    "**Q3.3** Implement load balancing:\n",
    "- Deploy 5 replicas of a web application\n",
    "- Make multiple requests and track which pod handles each\n",
    "- Analyze the load distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 4: ConfigMaps and Secrets [★★]\n",
    "\n",
    "### ConfigMaps\n",
    "\n",
    "ConfigMaps store non-sensitive configuration data.\n",
    "\n",
    "**configmap.yaml:**\n",
    "\n",
    "```yaml\n",
    "apiVersion: v1\n",
    "kind: ConfigMap\n",
    "metadata:\n",
    "  name: app-config\n",
    "data:\n",
    "  # Key-value pairs\n",
    "  DATABASE_HOST: \"postgres-service\"\n",
    "  DATABASE_PORT: \"5432\"\n",
    "  LOG_LEVEL: \"INFO\"\n",
    "  \n",
    "  # File-like keys\n",
    "  config.json: |\n",
    "    {\n",
    "      \"processing\": {\n",
    "        \"batch_size\": 100,\n",
    "        \"timeout\": 30\n",
    "      }\n",
    "    }\n",
    "```\n",
    "\n",
    "**Using ConfigMaps in Pods:**\n",
    "\n",
    "```yaml\n",
    "apiVersion: v1\n",
    "kind: Pod\n",
    "metadata:\n",
    "  name: config-demo\n",
    "spec:\n",
    "  containers:\n",
    "  - name: demo\n",
    "    image: python:3.10-slim\n",
    "    \n",
    "    # Method 1: Environment variables from specific keys\n",
    "    env:\n",
    "    - name: DB_HOST\n",
    "      valueFrom:\n",
    "        configMapKeyRef:\n",
    "          name: app-config\n",
    "          key: DATABASE_HOST\n",
    "    \n",
    "    # Method 2: All keys as environment variables\n",
    "    envFrom:\n",
    "    - configMapRef:\n",
    "        name: app-config\n",
    "    \n",
    "    # Method 3: Mount as volume\n",
    "    volumeMounts:\n",
    "    - name: config-volume\n",
    "      mountPath: /etc/config\n",
    "      \n",
    "  volumes:\n",
    "  - name: config-volume\n",
    "    configMap:\n",
    "      name: app-config\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Secrets\n",
    "\n",
    "Secrets store sensitive data like passwords and API keys.\n",
    "\n",
    "```bash\n",
    "# Create secret from literal values\n",
    "kubectl create secret generic db-credentials \\\n",
    "  --from-literal=username=admin \\\n",
    "  --from-literal=password=secretpass123\n",
    "\n",
    "# Create secret from file\n",
    "kubectl create secret generic tls-certs \\\n",
    "  --from-file=cert.pem \\\n",
    "  --from-file=key.pem\n",
    "\n",
    "# View secret (base64 encoded)\n",
    "kubectl get secret db-credentials -o yaml\n",
    "```\n",
    "\n",
    "**secret.yaml:**\n",
    "\n",
    "```yaml\n",
    "apiVersion: v1\n",
    "kind: Secret\n",
    "metadata:\n",
    "  name: db-credentials\n",
    "type: Opaque\n",
    "data:\n",
    "  # Values must be base64 encoded\n",
    "  # echo -n 'admin' | base64\n",
    "  username: YWRtaW4=\n",
    "  password: c2VjcmV0cGFzczEyMw==\n",
    "```\n",
    "\n",
    "**Using Secrets in Pods:**\n",
    "\n",
    "```yaml\n",
    "apiVersion: v1\n",
    "kind: Pod\n",
    "metadata:\n",
    "  name: secret-demo\n",
    "spec:\n",
    "  containers:\n",
    "  - name: demo\n",
    "    image: python:3.10-slim\n",
    "    env:\n",
    "    - name: DB_USERNAME\n",
    "      valueFrom:\n",
    "        secretKeyRef:\n",
    "          name: db-credentials\n",
    "          key: username\n",
    "    - name: DB_PASSWORD\n",
    "      valueFrom:\n",
    "        secretKeyRef:\n",
    "          name: db-credentials\n",
    "          key: password\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete Example: Application with Configuration\n",
    "\n",
    "**data-processor-config.yaml:**\n",
    "\n",
    "```yaml\n",
    "---\n",
    "apiVersion: v1\n",
    "kind: ConfigMap\n",
    "metadata:\n",
    "  name: processor-config\n",
    "data:\n",
    "  BATCH_SIZE: \"100\"\n",
    "  PROCESSING_MODE: \"parallel\"\n",
    "  LOG_LEVEL: \"DEBUG\"\n",
    "---\n",
    "apiVersion: v1\n",
    "kind: Secret\n",
    "metadata:\n",
    "  name: processor-secrets\n",
    "type: Opaque\n",
    "stringData:  # Use stringData for unencoded values\n",
    "  API_KEY: \"your-secret-api-key\"\n",
    "  DATABASE_URL: \"postgresql://user:pass@host:5432/db\"\n",
    "---\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: data-processor\n",
    "spec:\n",
    "  replicas: 2\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: data-processor\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: data-processor\n",
    "    spec:\n",
    "      containers:\n",
    "      - name: processor\n",
    "        image: python:3.10-slim\n",
    "        command: [\"python\", \"-c\"]\n",
    "        args:\n",
    "        - |\n",
    "          import os\n",
    "          import time\n",
    "          print(f\"Batch Size: {os.environ.get('BATCH_SIZE')}\")\n",
    "          print(f\"Mode: {os.environ.get('PROCESSING_MODE')}\")\n",
    "          print(f\"API Key: {os.environ.get('API_KEY')[:5]}...\")\n",
    "          while True:\n",
    "              print(\"Processing...\")\n",
    "              time.sleep(10)\n",
    "        envFrom:\n",
    "        - configMapRef:\n",
    "            name: processor-config\n",
    "        - secretRef:\n",
    "            name: processor-secrets\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions - Exercise 4\n",
    "\n",
    "**Q4.1** Create configuration for a data processing application:\n",
    "- ConfigMap with processing parameters (batch size, timeout, input/output paths)\n",
    "- Secret with database credentials\n",
    "- Deployment that uses both\n",
    "\n",
    "**Q4.2** Implement configuration hot-reloading:\n",
    "- Mount ConfigMap as a volume\n",
    "- Write a Python script that watches for config file changes\n",
    "- Update the ConfigMap and verify the application detects changes\n",
    "\n",
    "**Q4.3** Create a production-ready configuration setup:\n",
    "- Separate configs for dev/staging/prod environments\n",
    "- Use Kustomize to manage environment-specific overrides\n",
    "- Document the configuration management strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 5: Persistent Storage [★★]\n",
    "\n",
    "### Storage Concepts\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────┐\n",
    "│                     Storage Architecture                     │\n",
    "│                                                              │\n",
    "│  ┌──────────────────┐                                       │\n",
    "│  │       Pod        │                                       │\n",
    "│  │  ┌────────────┐  │                                       │\n",
    "│  │  │  Volume    │  │◄──── PersistentVolumeClaim (PVC)     │\n",
    "│  │  │  Mount     │  │            │                          │\n",
    "│  │  └────────────┘  │            │ binds                    │\n",
    "│  └──────────────────┘            ▼                          │\n",
    "│                         ┌──────────────────┐                │\n",
    "│                         │ PersistentVolume │                │\n",
    "│                         │      (PV)        │                │\n",
    "│                         └────────┬─────────┘                │\n",
    "│                                  │                          │\n",
    "│                                  ▼                          │\n",
    "│                         ┌──────────────────┐                │\n",
    "│                         │ Storage Backend  │                │\n",
    "│                         │ (NFS, EBS, etc.) │                │\n",
    "│                         └──────────────────┘                │\n",
    "└─────────────────────────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PersistentVolume and PersistentVolumeClaim\n",
    "\n",
    "**pv-pvc.yaml:**\n",
    "\n",
    "```yaml\n",
    "---\n",
    "# PersistentVolume (usually created by admin)\n",
    "apiVersion: v1\n",
    "kind: PersistentVolume\n",
    "metadata:\n",
    "  name: data-pv\n",
    "spec:\n",
    "  capacity:\n",
    "    storage: 5Gi\n",
    "  accessModes:\n",
    "    - ReadWriteOnce      # RWO: single node\n",
    "    # - ReadWriteMany    # RWX: multiple nodes\n",
    "    # - ReadOnlyMany     # ROX: read-only multiple nodes\n",
    "  persistentVolumeReclaimPolicy: Retain  # or Delete\n",
    "  storageClassName: manual\n",
    "  hostPath:\n",
    "    path: /data/pv-data\n",
    "---\n",
    "# PersistentVolumeClaim (created by user)\n",
    "apiVersion: v1\n",
    "kind: PersistentVolumeClaim\n",
    "metadata:\n",
    "  name: data-pvc\n",
    "spec:\n",
    "  accessModes:\n",
    "    - ReadWriteOnce\n",
    "  resources:\n",
    "    requests:\n",
    "      storage: 2Gi\n",
    "  storageClassName: manual\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using PVC in Pods\n",
    "\n",
    "**pod-with-storage.yaml:**\n",
    "\n",
    "```yaml\n",
    "apiVersion: v1\n",
    "kind: Pod\n",
    "metadata:\n",
    "  name: data-writer\n",
    "spec:\n",
    "  containers:\n",
    "  - name: writer\n",
    "    image: python:3.10-slim\n",
    "    command: [\"python\", \"-c\"]\n",
    "    args:\n",
    "    - |\n",
    "      import time\n",
    "      from datetime import datetime\n",
    "      \n",
    "      counter = 0\n",
    "      while True:\n",
    "          with open('/data/output.txt', 'a') as f:\n",
    "              f.write(f\"{datetime.now()}: Record {counter}\\n\")\n",
    "          print(f\"Written record {counter}\")\n",
    "          counter += 1\n",
    "          time.sleep(5)\n",
    "    volumeMounts:\n",
    "    - name: data-volume\n",
    "      mountPath: /data\n",
    "  volumes:\n",
    "  - name: data-volume\n",
    "    persistentVolumeClaim:\n",
    "      claimName: data-pvc\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StorageClass for Dynamic Provisioning\n",
    "\n",
    "**storageclass.yaml:**\n",
    "\n",
    "```yaml\n",
    "apiVersion: storage.k8s.io/v1\n",
    "kind: StorageClass\n",
    "metadata:\n",
    "  name: fast-storage\n",
    "provisioner: kubernetes.io/gce-pd  # or aws-ebs, azure-disk\n",
    "parameters:\n",
    "  type: pd-ssd\n",
    "reclaimPolicy: Delete\n",
    "volumeBindingMode: Immediate\n",
    "```\n",
    "\n",
    "**Dynamic PVC:**\n",
    "\n",
    "```yaml\n",
    "apiVersion: v1\n",
    "kind: PersistentVolumeClaim\n",
    "metadata:\n",
    "  name: dynamic-pvc\n",
    "spec:\n",
    "  accessModes:\n",
    "    - ReadWriteOnce\n",
    "  resources:\n",
    "    requests:\n",
    "      storage: 10Gi\n",
    "  storageClassName: fast-storage  # Uses StorageClass\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions - Exercise 5\n",
    "\n",
    "**Q5.1** Create a persistent storage setup for a data pipeline:\n",
    "- PersistentVolume for input data\n",
    "- PersistentVolume for output data\n",
    "- Pod that reads from input, processes, writes to output\n",
    "\n",
    "**Q5.2** Implement data sharing between pods:\n",
    "- Create a PVC with ReadWriteMany access mode\n",
    "- Deploy a writer pod and multiple reader pods\n",
    "- Verify all pods can access the shared data\n",
    "\n",
    "**Q5.3** Test data persistence:\n",
    "- Deploy a database (PostgreSQL) with persistent storage\n",
    "- Insert data, delete the pod, verify data persists\n",
    "- Document the backup and restore process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 6: Jobs and CronJobs for Batch Processing [★★]\n",
    "\n",
    "### Jobs\n",
    "\n",
    "Jobs run one or more pods to completion.\n",
    "\n",
    "**job.yaml:**\n",
    "\n",
    "```yaml\n",
    "apiVersion: batch/v1\n",
    "kind: Job\n",
    "metadata:\n",
    "  name: data-processing-job\n",
    "spec:\n",
    "  completions: 5       # Number of successful completions required\n",
    "  parallelism: 2       # Pods running in parallel\n",
    "  backoffLimit: 3      # Retries before marking as failed\n",
    "  activeDeadlineSeconds: 600  # Timeout\n",
    "  template:\n",
    "    spec:\n",
    "      restartPolicy: Never  # or OnFailure\n",
    "      containers:\n",
    "      - name: processor\n",
    "        image: python:3.10-slim\n",
    "        command: [\"python\", \"-c\"]\n",
    "        args:\n",
    "        - |\n",
    "          import random\n",
    "          import time\n",
    "          import socket\n",
    "          \n",
    "          hostname = socket.gethostname()\n",
    "          work_time = random.randint(5, 15)\n",
    "          \n",
    "          print(f\"Job {hostname} starting, will run for {work_time} seconds\")\n",
    "          time.sleep(work_time)\n",
    "          print(f\"Job {hostname} completed successfully\")\n",
    "```\n",
    "\n",
    "```bash\n",
    "# Create job\n",
    "kubectl apply -f job.yaml\n",
    "\n",
    "# Watch job progress\n",
    "kubectl get jobs -w\n",
    "\n",
    "# View pod logs\n",
    "kubectl logs job/data-processing-job\n",
    "\n",
    "# Delete job and its pods\n",
    "kubectl delete job data-processing-job\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CronJobs\n",
    "\n",
    "CronJobs run jobs on a schedule.\n",
    "\n",
    "**cronjob.yaml:**\n",
    "\n",
    "```yaml\n",
    "apiVersion: batch/v1\n",
    "kind: CronJob\n",
    "metadata:\n",
    "  name: data-aggregator\n",
    "spec:\n",
    "  schedule: \"*/5 * * * *\"  # Every 5 minutes\n",
    "  # Cron format: minute hour day-of-month month day-of-week\n",
    "  # \"0 * * * *\"     - Every hour\n",
    "  # \"0 0 * * *\"     - Every day at midnight\n",
    "  # \"0 0 * * 0\"     - Every Sunday at midnight\n",
    "  \n",
    "  concurrencyPolicy: Forbid  # Allow, Forbid, Replace\n",
    "  successfulJobsHistoryLimit: 3\n",
    "  failedJobsHistoryLimit: 1\n",
    "  startingDeadlineSeconds: 200\n",
    "  \n",
    "  jobTemplate:\n",
    "    spec:\n",
    "      template:\n",
    "        spec:\n",
    "          restartPolicy: OnFailure\n",
    "          containers:\n",
    "          - name: aggregator\n",
    "            image: python:3.10-slim\n",
    "            command: [\"python\", \"-c\"]\n",
    "            args:\n",
    "            - |\n",
    "              from datetime import datetime\n",
    "              print(f\"Running aggregation at {datetime.now()}\")\n",
    "              # Simulate aggregation work\n",
    "              import time\n",
    "              time.sleep(30)\n",
    "              print(\"Aggregation complete\")\n",
    "```\n",
    "\n",
    "```bash\n",
    "# Create cronjob\n",
    "kubectl apply -f cronjob.yaml\n",
    "\n",
    "# List cronjobs\n",
    "kubectl get cronjobs\n",
    "\n",
    "# View jobs created by cronjob\n",
    "kubectl get jobs\n",
    "\n",
    "# Manually trigger a job from cronjob\n",
    "kubectl create job --from=cronjob/data-aggregator manual-run\n",
    "\n",
    "# Suspend a cronjob\n",
    "kubectl patch cronjob data-aggregator -p '{\"spec\": {\"suspend\": true}}'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing Pipeline with Jobs\n",
    "\n",
    "**etl-pipeline.yaml:**\n",
    "\n",
    "```yaml\n",
    "---\n",
    "apiVersion: v1\n",
    "kind: ConfigMap\n",
    "metadata:\n",
    "  name: etl-config\n",
    "data:\n",
    "  INPUT_PATH: \"/data/input\"\n",
    "  OUTPUT_PATH: \"/data/output\"\n",
    "---\n",
    "apiVersion: batch/v1\n",
    "kind: Job\n",
    "metadata:\n",
    "  name: etl-extract\n",
    "spec:\n",
    "  template:\n",
    "    spec:\n",
    "      restartPolicy: OnFailure\n",
    "      containers:\n",
    "      - name: extract\n",
    "        image: python:3.10-slim\n",
    "        command: [\"python\", \"-c\"]\n",
    "        args:\n",
    "        - |\n",
    "          import os\n",
    "          import json\n",
    "          \n",
    "          output_path = os.environ.get('OUTPUT_PATH', '/data/output')\n",
    "          os.makedirs(output_path, exist_ok=True)\n",
    "          \n",
    "          # Simulate extraction\n",
    "          data = [{'id': i, 'value': i * 10} for i in range(100)]\n",
    "          \n",
    "          with open(f'{output_path}/extracted.json', 'w') as f:\n",
    "              json.dump(data, f)\n",
    "          \n",
    "          print(f\"Extracted {len(data)} records\")\n",
    "        envFrom:\n",
    "        - configMapRef:\n",
    "            name: etl-config\n",
    "        volumeMounts:\n",
    "        - name: data-volume\n",
    "          mountPath: /data\n",
    "      volumes:\n",
    "      - name: data-volume\n",
    "        persistentVolumeClaim:\n",
    "          claimName: etl-data-pvc\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions - Exercise 6\n",
    "\n",
    "**Q6.1** Create a batch processing job that:\n",
    "- Reads data from a ConfigMap\n",
    "- Processes data in parallel (3 pods)\n",
    "- Writes results to a PersistentVolume\n",
    "- Handles failures with retries\n",
    "\n",
    "**Q6.2** Implement a scheduled data pipeline:\n",
    "- CronJob that runs hourly\n",
    "- Fetches data from an external API (simulated)\n",
    "- Processes and stores results\n",
    "- Sends notification on completion (simulated)\n",
    "\n",
    "**Q6.3** Create an ETL pipeline with multiple jobs:\n",
    "- Extract job that fetches raw data\n",
    "- Transform job that cleans and enriches data\n",
    "- Load job that writes to final destination\n",
    "- Use initContainers to ensure proper sequencing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 7: Horizontal Pod Autoscaling [★★★]\n",
    "\n",
    "### HPA Basics\n",
    "\n",
    "The Horizontal Pod Autoscaler automatically scales the number of pods based on observed CPU/memory utilization or custom metrics.\n",
    "\n",
    "```bash\n",
    "# Enable metrics-server (required for HPA)\n",
    "# For minikube:\n",
    "minikube addons enable metrics-server\n",
    "\n",
    "# Verify metrics are available\n",
    "kubectl top nodes\n",
    "kubectl top pods\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HPA Configuration\n",
    "\n",
    "**deployment-for-hpa.yaml:**\n",
    "\n",
    "```yaml\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: cpu-intensive-app\n",
    "spec:\n",
    "  replicas: 1\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: cpu-intensive\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: cpu-intensive\n",
    "    spec:\n",
    "      containers:\n",
    "      - name: app\n",
    "        image: python:3.10-slim\n",
    "        command: [\"/bin/bash\", \"-c\"]\n",
    "        args:\n",
    "        - |\n",
    "          pip install flask && python -c \"\n",
    "          from flask import Flask\n",
    "          import math\n",
    "          app = Flask(__name__)\n",
    "          @app.route('/')\n",
    "          def compute():\n",
    "              x = 0\n",
    "              for i in range(1000000):\n",
    "                  x += math.sqrt(i)\n",
    "              return f'Computed: {x}'\n",
    "          app.run(host='0.0.0.0', port=5000)\n",
    "          \"\n",
    "        ports:\n",
    "        - containerPort: 5000\n",
    "        resources:\n",
    "          requests:\n",
    "            cpu: \"100m\"\n",
    "            memory: \"128Mi\"\n",
    "          limits:\n",
    "            cpu: \"500m\"\n",
    "            memory: \"256Mi\"\n",
    "---\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  name: cpu-intensive-service\n",
    "spec:\n",
    "  type: NodePort\n",
    "  selector:\n",
    "    app: cpu-intensive\n",
    "  ports:\n",
    "  - port: 80\n",
    "    targetPort: 5000\n",
    "    nodePort: 30600\n",
    "```\n",
    "\n",
    "**hpa.yaml:**\n",
    "\n",
    "```yaml\n",
    "apiVersion: autoscaling/v2\n",
    "kind: HorizontalPodAutoscaler\n",
    "metadata:\n",
    "  name: cpu-intensive-hpa\n",
    "spec:\n",
    "  scaleTargetRef:\n",
    "    apiVersion: apps/v1\n",
    "    kind: Deployment\n",
    "    name: cpu-intensive-app\n",
    "  minReplicas: 1\n",
    "  maxReplicas: 10\n",
    "  metrics:\n",
    "  - type: Resource\n",
    "    resource:\n",
    "      name: cpu\n",
    "      target:\n",
    "        type: Utilization\n",
    "        averageUtilization: 50\n",
    "  behavior:\n",
    "    scaleDown:\n",
    "      stabilizationWindowSeconds: 300\n",
    "      policies:\n",
    "      - type: Percent\n",
    "        value: 100\n",
    "        periodSeconds: 15\n",
    "    scaleUp:\n",
    "      stabilizationWindowSeconds: 0\n",
    "      policies:\n",
    "      - type: Percent\n",
    "        value: 100\n",
    "        periodSeconds: 15\n",
    "      - type: Pods\n",
    "        value: 4\n",
    "        periodSeconds: 15\n",
    "      selectPolicy: Max\n",
    "```\n",
    "\n",
    "```bash\n",
    "# Apply configurations\n",
    "kubectl apply -f deployment-for-hpa.yaml\n",
    "kubectl apply -f hpa.yaml\n",
    "\n",
    "# Or create HPA via command line\n",
    "kubectl autoscale deployment cpu-intensive-app --cpu-percent=50 --min=1 --max=10\n",
    "\n",
    "# Watch HPA status\n",
    "kubectl get hpa -w\n",
    "\n",
    "# Generate load\n",
    "# In another terminal:\n",
    "kubectl run -it load-generator --rm --image=busybox -- /bin/sh -c \\\n",
    "  \"while true; do wget -q -O- http://cpu-intensive-service; done\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory-based HPA\n",
    "\n",
    "```yaml\n",
    "apiVersion: autoscaling/v2\n",
    "kind: HorizontalPodAutoscaler\n",
    "metadata:\n",
    "  name: memory-hpa\n",
    "spec:\n",
    "  scaleTargetRef:\n",
    "    apiVersion: apps/v1\n",
    "    kind: Deployment\n",
    "    name: memory-intensive-app\n",
    "  minReplicas: 2\n",
    "  maxReplicas: 8\n",
    "  metrics:\n",
    "  - type: Resource\n",
    "    resource:\n",
    "      name: memory\n",
    "      target:\n",
    "        type: AverageValue\n",
    "        averageValue: 500Mi\n",
    "  - type: Resource\n",
    "    resource:\n",
    "      name: cpu\n",
    "      target:\n",
    "        type: Utilization\n",
    "        averageUtilization: 70\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions - Exercise 7\n",
    "\n",
    "**Q7.1** Configure autoscaling for a data processing service:\n",
    "- Deploy a CPU-intensive processing application\n",
    "- Configure HPA with min=2, max=10 replicas\n",
    "- Target CPU utilization at 60%\n",
    "- Test with varying load levels\n",
    "\n",
    "**Q7.2** Implement multi-metric scaling:\n",
    "- Scale based on both CPU and memory\n",
    "- Add custom metrics (if using Prometheus)\n",
    "- Document the scaling behavior under different conditions\n",
    "\n",
    "**Q7.3** Create a complete auto-scaling demo:\n",
    "- Deploy application with HPA\n",
    "- Create load generator\n",
    "- Visualize scaling events\n",
    "- Measure response times during scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 8: Deploying Data Processing Pipelines [★★★]\n",
    "\n",
    "### Complete Data Pipeline Architecture\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────┐\n",
    "│                    Kubernetes Cluster                           │\n",
    "│                                                                 │\n",
    "│  ┌─────────────┐     ┌─────────────┐     ┌─────────────┐       │\n",
    "│  │   Data      │     │   Message   │     │   Worker    │       │\n",
    "│  │  Ingester   │────►│   Queue     │────►│   Pods      │       │\n",
    "│  │  (Deploy)   │     │ (RabbitMQ)  │     │  (Deploy)   │       │\n",
    "│  └─────────────┘     └─────────────┘     └──────┬──────┘       │\n",
    "│                                                  │              │\n",
    "│                                                  ▼              │\n",
    "│                                           ┌─────────────┐       │\n",
    "│                                           │  Database   │       │\n",
    "│                                           │ (PostgreSQL)│       │\n",
    "│                                           └─────────────┘       │\n",
    "│                                                  │              │\n",
    "│                                                  ▼              │\n",
    "│                                           ┌─────────────┐       │\n",
    "│                                           │    API      │       │\n",
    "│                                           │  (Deploy)   │       │\n",
    "│                                           └─────────────┘       │\n",
    "└─────────────────────────────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RabbitMQ Deployment\n",
    "\n",
    "**rabbitmq.yaml:**\n",
    "\n",
    "```yaml\n",
    "---\n",
    "apiVersion: v1\n",
    "kind: ConfigMap\n",
    "metadata:\n",
    "  name: rabbitmq-config\n",
    "data:\n",
    "  RABBITMQ_DEFAULT_USER: \"admin\"\n",
    "  RABBITMQ_DEFAULT_PASS: \"rabbitmq123\"\n",
    "---\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: rabbitmq\n",
    "spec:\n",
    "  replicas: 1\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: rabbitmq\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: rabbitmq\n",
    "    spec:\n",
    "      containers:\n",
    "      - name: rabbitmq\n",
    "        image: rabbitmq:3-management\n",
    "        ports:\n",
    "        - containerPort: 5672\n",
    "        - containerPort: 15672\n",
    "        envFrom:\n",
    "        - configMapRef:\n",
    "            name: rabbitmq-config\n",
    "        resources:\n",
    "          requests:\n",
    "            memory: \"256Mi\"\n",
    "            cpu: \"200m\"\n",
    "          limits:\n",
    "            memory: \"512Mi\"\n",
    "            cpu: \"500m\"\n",
    "---\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  name: rabbitmq\n",
    "spec:\n",
    "  selector:\n",
    "    app: rabbitmq\n",
    "  ports:\n",
    "  - name: amqp\n",
    "    port: 5672\n",
    "  - name: management\n",
    "    port: 15672\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PostgreSQL Deployment\n",
    "\n",
    "**postgres.yaml:**\n",
    "\n",
    "```yaml\n",
    "---\n",
    "apiVersion: v1\n",
    "kind: Secret\n",
    "metadata:\n",
    "  name: postgres-secret\n",
    "type: Opaque\n",
    "stringData:\n",
    "  POSTGRES_USER: \"datauser\"\n",
    "  POSTGRES_PASSWORD: \"datapass123\"\n",
    "  POSTGRES_DB: \"dataprocessing\"\n",
    "---\n",
    "apiVersion: v1\n",
    "kind: PersistentVolumeClaim\n",
    "metadata:\n",
    "  name: postgres-pvc\n",
    "spec:\n",
    "  accessModes:\n",
    "    - ReadWriteOnce\n",
    "  resources:\n",
    "    requests:\n",
    "      storage: 5Gi\n",
    "---\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: postgres\n",
    "spec:\n",
    "  replicas: 1\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: postgres\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: postgres\n",
    "    spec:\n",
    "      containers:\n",
    "      - name: postgres\n",
    "        image: postgres:15\n",
    "        ports:\n",
    "        - containerPort: 5432\n",
    "        envFrom:\n",
    "        - secretRef:\n",
    "            name: postgres-secret\n",
    "        volumeMounts:\n",
    "        - name: postgres-storage\n",
    "          mountPath: /var/lib/postgresql/data\n",
    "        resources:\n",
    "          requests:\n",
    "            memory: \"256Mi\"\n",
    "            cpu: \"200m\"\n",
    "          limits:\n",
    "            memory: \"512Mi\"\n",
    "            cpu: \"500m\"\n",
    "      volumes:\n",
    "      - name: postgres-storage\n",
    "        persistentVolumeClaim:\n",
    "          claimName: postgres-pvc\n",
    "---\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  name: postgres\n",
    "spec:\n",
    "  selector:\n",
    "    app: postgres\n",
    "  ports:\n",
    "  - port: 5432\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Worker Deployment with HPA\n",
    "\n",
    "**worker.yaml:**\n",
    "\n",
    "```yaml\n",
    "---\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: data-worker\n",
    "spec:\n",
    "  replicas: 2\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: data-worker\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: data-worker\n",
    "    spec:\n",
    "      containers:\n",
    "      - name: worker\n",
    "        image: python:3.10-slim\n",
    "        command: [\"/bin/bash\", \"-c\"]\n",
    "        args:\n",
    "        - |\n",
    "          pip install pika psycopg2-binary && python -c \"\n",
    "          import pika\n",
    "          import psycopg2\n",
    "          import time\n",
    "          import os\n",
    "          import json\n",
    "          \n",
    "          # Connect to RabbitMQ\n",
    "          for i in range(10):\n",
    "              try:\n",
    "                  connection = pika.BlockingConnection(\n",
    "                      pika.ConnectionParameters('rabbitmq', credentials=pika.PlainCredentials('admin', 'rabbitmq123'))\n",
    "                  )\n",
    "                  break\n",
    "              except:\n",
    "                  print('Waiting for RabbitMQ...')\n",
    "                  time.sleep(5)\n",
    "          \n",
    "          channel = connection.channel()\n",
    "          channel.queue_declare(queue='data_queue', durable=True)\n",
    "          \n",
    "          def callback(ch, method, props, body):\n",
    "              data = json.loads(body)\n",
    "              print(f'Processing: {data}')\n",
    "              # Process data and save to database\n",
    "              time.sleep(1)\n",
    "              ch.basic_ack(delivery_tag=method.delivery_tag)\n",
    "          \n",
    "          channel.basic_qos(prefetch_count=1)\n",
    "          channel.basic_consume(queue='data_queue', on_message_callback=callback)\n",
    "          print('Worker started, waiting for messages...')\n",
    "          channel.start_consuming()\n",
    "          \"\n",
    "        resources:\n",
    "          requests:\n",
    "            memory: \"128Mi\"\n",
    "            cpu: \"100m\"\n",
    "          limits:\n",
    "            memory: \"256Mi\"\n",
    "            cpu: \"300m\"\n",
    "---\n",
    "apiVersion: autoscaling/v2\n",
    "kind: HorizontalPodAutoscaler\n",
    "metadata:\n",
    "  name: data-worker-hpa\n",
    "spec:\n",
    "  scaleTargetRef:\n",
    "    apiVersion: apps/v1\n",
    "    kind: Deployment\n",
    "    name: data-worker\n",
    "  minReplicas: 2\n",
    "  maxReplicas: 10\n",
    "  metrics:\n",
    "  - type: Resource\n",
    "    resource:\n",
    "      name: cpu\n",
    "      target:\n",
    "        type: Utilization\n",
    "        averageUtilization: 60\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploying the Complete Pipeline\n",
    "\n",
    "```bash\n",
    "# Create namespace\n",
    "kubectl create namespace data-pipeline\n",
    "\n",
    "# Deploy components\n",
    "kubectl apply -f rabbitmq.yaml -n data-pipeline\n",
    "kubectl apply -f postgres.yaml -n data-pipeline\n",
    "kubectl apply -f worker.yaml -n data-pipeline\n",
    "\n",
    "# Verify deployments\n",
    "kubectl get all -n data-pipeline\n",
    "\n",
    "# View logs\n",
    "kubectl logs -f deployment/data-worker -n data-pipeline\n",
    "\n",
    "# Port forward for debugging\n",
    "kubectl port-forward svc/rabbitmq 15672:15672 -n data-pipeline\n",
    "# Access RabbitMQ UI: http://localhost:15672\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions - Exercise 8\n",
    "\n",
    "**Q8.1** Deploy a complete data processing pipeline:\n",
    "- RabbitMQ for message queuing\n",
    "- PostgreSQL for data storage\n",
    "- Producer service that generates data\n",
    "- Worker service with auto-scaling\n",
    "- API service to query results\n",
    "\n",
    "**Q8.2** Add monitoring and observability:\n",
    "- Deploy Prometheus for metrics collection\n",
    "- Configure scraping for all services\n",
    "- Create Grafana dashboards\n",
    "- Set up alerts for key metrics\n",
    "\n",
    "**Q8.3** Implement a Spark on Kubernetes deployment:\n",
    "- Deploy Spark operator (or use spark-submit with Kubernetes)\n",
    "- Submit a Spark job to process data from PostgreSQL\n",
    "- Configure executor scaling\n",
    "- Monitor job progress and resource usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this practical, you learned:\n",
    "\n",
    "1. **Kubernetes Architecture**: Control plane, worker nodes, and core components\n",
    "2. **Pods and Deployments**: Creating and managing containerized applications\n",
    "3. **Services**: Exposing applications and enabling service discovery\n",
    "4. **ConfigMaps and Secrets**: Managing application configuration\n",
    "5. **Persistent Storage**: Implementing data persistence with PVs and PVCs\n",
    "6. **Jobs and CronJobs**: Running batch and scheduled workloads\n",
    "7. **Horizontal Pod Autoscaling**: Automatically scaling based on metrics\n",
    "8. **Complete Pipelines**: Deploying production-ready data processing systems\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- Use Deployments for stateless applications, StatefulSets for stateful ones\n",
    "- Always define resource requests and limits\n",
    "- Use ConfigMaps for configuration, Secrets for sensitive data\n",
    "- Implement health checks (liveness and readiness probes)\n",
    "- Design for horizontal scaling from the start\n",
    "- Use namespaces for resource isolation and organization\n",
    "\n",
    "### Production Considerations\n",
    "\n",
    "- **Security**: Use RBAC, Network Policies, Pod Security Policies\n",
    "- **Monitoring**: Implement comprehensive observability\n",
    "- **High Availability**: Deploy across multiple availability zones\n",
    "- **Disaster Recovery**: Regular backups and tested recovery procedures\n",
    "- **GitOps**: Use tools like ArgoCD or Flux for declarative deployments\n",
    "\n",
    "### Further Reading\n",
    "\n",
    "- [Kubernetes Documentation](https://kubernetes.io/docs/home/)\n",
    "- [Kubernetes Patterns](https://www.oreilly.com/library/view/kubernetes-patterns/9781492050278/)\n",
    "- [The Kubernetes Book](https://nigelpoulton.com/books/)\n",
    "- [Spark on Kubernetes](https://spark.apache.org/docs/latest/running-on-kubernetes.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
